{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Need for Change: North Carolina School Performance\n",
    "\n",
    "Out of the 2,617 public schools (including Charter) operating in North Carolina during the 2016-2017 school year, 902 schools (34.5%) have, for at least one year since 2013-2014, been classified as a low performing school. \n",
    "\n",
    "NCPDI classifies low performing schools as:\n",
    "\n",
    "“Low-performing schools are those that receive a **school performance grade** of **D** or **F** and a **school growth score** of **\"met expected growth\"** or **\"not met expected growth\"** as defined by G.S. 115C-83.15.” (G.S. 115C-105.37(a)), and\n",
    "\n",
    "“A Low-performing local school administrative unit is a unit in which the majority of the schools in that unit that received a school performance grade and school growth score as provided in G.S. 115C-83.15 have been identified as low-performing schools, as provided in G.S. 115C-105.37.” (G.S. 115C-105.39A(a)).\n",
    "\n",
    "Source: http://www.ncpublicschools.org/schooltransformation/low-performing/\n",
    "\n",
    "**Thus, we treat low performing schools as a proxy for aggregate student educational achievement.**\n",
    "\n",
    "\n",
    "## Problem Statement: \n",
    "In recent years, 30% of public schools in North Carolina have been low performing. Students in low performing schools are not meeting the educational achievement standards set by the state. Factors outside administrators' control: economically disadvantaged and majority-minority student populations, are the most influential indicators of low performance.  \n",
    "\n",
    "\n",
    "## Motivation: \n",
    "Of the 902 schools low performing between 2013/14 and 2016/17, 209 have been low performing for all schools years (8%), 203 have been low performing for 3 of the schools years (7.8%), 227 have been low performing for 2 schools years (8.7%), and 263 have been low performing once (10%). Another way to look at these numbers is to consider that out of the four school years between 2013/14 and 2016/2017, 24.4% of schools have been recurringly low performing. \n",
    "\n",
    "What does this mean in terms of students? \n",
    "Out of around the 1.5 million total number of students studying in a public school in the 2016/17 school year, around 460,000 of those students (30%) have had at least a year studying a low performing school. Around 100,000 students (6.8%) in North Carolina study at a school that has been low performing for 4 years. \n",
    "\n",
    "\n",
    "## Solution:\n",
    "We identify the factors within school administrator's control that can positively impact a school's EVAAS growth score. Growth scores are a metric to measure how well a school's performance increases over a year. We focus on growth instead of raw performance scores, as raw scores will be much slower to change over time. \n",
    "\n",
    "This notebook reviews NCPDI North Carolina School Report Card and Statistical Profile data to identify the factors that contribute to low school performance and EVAAS growth scores. We will then create a model to predict EVAAS growth scores including only school-level factors irrespective of student demographics. After determining the most predictive factors for determining EVAAS growth scores, we simulate changes in these factors to demonstrate a theoretical improvement in student achievement growth. \n",
    "\n",
    "We: \n",
    "1. Take a look at the heuristically most common reasons for low school performance: percentage of economically disadvantaged students, student demographics, and school funding to see if these indicators are statistically different in low performing schools. \n",
    "\n",
    "2. Remove the factors outside of the school adminsitration's control from the dataset to determine which school-level factors are most important in determining low performance by:\n",
    "    1. Performing Feature Importance using XGBoost. XGBoost is a tree-based gradient-boosting method which minimizes a cost function relative to predicting a target variable. When a node in a decision tree is split, we can calculate the following reduction in impurity, and attribute this reduction to feature involved. When the tree is finished splitting nodes, those features with the largest proportional contribution toward decreasing impurity within nodes can be said to be the most “important.”\n",
    "    \n",
    "4. **Test the predictive nature of our selected features by creating a classification model to predict the EVAAS growth score for each of our 4 years. Whether these features are important will be reflected in the accuracy and precision of the regression model. **\n",
    "\n",
    "5. Use a new methodology for decision-making. We create a function that will synthesize data based on percent changes in a certain input feature to then be used in our regression model to predict low performance. This will allow us to review, all things being equal, how a change in one or more features may correlate to a change in school EVAAS growth score. \n",
    "\n",
    "\n",
    "*Please note: Dataset Creation and Processing can be found: https://github.com/oleeson/NCPDI-Capstone*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Change Dir to Import Dataset for EDA \n",
    "os.chdir(\"..\")\n",
    "cwd = os.getcwd()\n",
    "cwd = cwd + \"/DatasetCreation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Read in Schools Dataset\n",
    "df_14 = pd.read_csv(cwd+'/2014/PublicSchools2014_LPS_Processed.csv')\n",
    "df_15 = pd.read_csv(cwd+'/2015/PublicSchools2015_LPS_Processed.csv')\n",
    "df_16 = pd.read_csv(cwd+'/2016/PublicSchools2016_LPS_Processed.csv')\n",
    "df_17 = pd.read_csv(cwd+'/2017/PublicSchools2017_LPS_Processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Column Subsets\n",
    "profileCols = ['title1_type_cd',\n",
    " 'clp_ind',\n",
    " 'focus_clp_ind',\n",
    " 'summer_program_ind',\n",
    " 'asm_no_spg_ind',\n",
    " 'no_data_spg_ind',\n",
    " 'student_num',\n",
    " 'lea_avg_student_num',\n",
    " 'Grad_project_status', \n",
    " 'category_cd_E',\n",
    " 'category_cd_H',\n",
    " 'category_cd_I',\n",
    " 'category_cd_M',\n",
    " 'category_cd_T',\n",
    " 'esea_status_Esea_Pass',\n",
    " 'esea_status_Non_Esea',\n",
    " 'SBE District_Northeast',\n",
    " 'SBE District_Northwest',\n",
    " 'SBE District_Piedmont-Triad',\n",
    " 'SBE District_Sandhills',\n",
    " 'SBE District_Southeast',\n",
    " 'SBE District_Southwest',\n",
    " 'SBE District_Western']\n",
    "\n",
    "demographicCols = ['AsianFemalePct',\n",
    " 'AsianMalePct',\n",
    " 'AsianPct',\n",
    " 'BlackFemalePct',\n",
    " 'BlackMalePct',\n",
    " 'BlackPct',\n",
    " 'HispanicFemalePct',\n",
    " 'HispanicMalePct',\n",
    " 'HispanicPct',\n",
    " 'IndianFemalePct',\n",
    " 'IndianMalePct',\n",
    " 'IndianPct',\n",
    " 'MinorityFemalePct',\n",
    " 'MinorityMalePct',\n",
    " 'MinorityPct',\n",
    " 'PacificIslandFemalePct',\n",
    " 'PacificIslandMalePct',\n",
    " 'PacificIslandPct',\n",
    " 'TwoOrMoreFemalePct',\n",
    " 'TwoOrMoreMalePct',\n",
    " 'TwoOrMorePct',\n",
    " 'WhiteFemalePct',\n",
    " 'WhiteMalePct',\n",
    " 'WhitePct',\n",
    " 'pct_eds']\n",
    "\n",
    "environmentCols = ['avg_daily_attend_pct',\n",
    " 'crime_per_c_num',\n",
    " 'short_susp_per_c_num',\n",
    " 'long_susp_per_c_num',\n",
    " 'expelled_per_c_num',\n",
    " 'stud_internet_comp_num',\n",
    " 'lea_avg_daily_attend_pct',\n",
    " 'lea_crime_per_c_num',\n",
    " 'lea_short_susp_per_c_num',\n",
    " 'lea_long_susp_per_c_num',\n",
    " 'lea_expelled_per_c_num',\n",
    " 'lea_stud_internet_comp_num',\n",
    " 'digital_media_pct',\n",
    " 'avg_age_media_collection',\n",
    " 'books_per_student',\n",
    " 'lea_avg_age_media_collection',\n",
    " 'lea_books_per_student',\n",
    " 'wap_num',\n",
    " 'wap_per_classroom',\n",
    " 'lea_wap_num',\n",
    " 'lea_wap_per_classroom',\n",
    " 'Byod_Yes',\n",
    " '_1_to_1_access_Yes',\n",
    " 'SRC_devices_sent_home_Yes']\n",
    "\n",
    "educatorCols = ['flicensed_teach_pct',\n",
    " 'tchyrs_0thru3_pct',\n",
    " 'tchyrs_4thru10_pct',\n",
    " 'tchyrs_11plus_pct',\n",
    " 'class_teach_num',\n",
    " 'nbpts_num',\n",
    " 'advance_dgr_pct',\n",
    " '_1yr_tchr_trnovr_pct',\n",
    " 'lea_flicensed_teach_pct',\n",
    " 'lea_tchyrs_0thru3_pct',\n",
    " 'lea_tchyrs_4thru10_pct',\n",
    " 'lea_tchyrs_11plus_pct',\n",
    " 'lea_class_teach_num',\n",
    " 'lea_nbpts_num',\n",
    " 'lea_advance_dgr_pct',\n",
    " 'lea_1yr_tchr_trnovr_pct',\n",
    " 'lea_lateral_teach_pct',\n",
    " '0-3 Years_Exp_Pct_Tch',\n",
    " '10+ Years_Exp_Pct_Tch',\n",
    " '4-10 Years_Exp_Pct_Tch',\n",
    " '0-3 Years_LEA_Exp_Pct_Prin',\n",
    " '10+ Years_LEA_Exp_Pct_Prin',\n",
    " '4-10 Years_LEA_Exp_Pct_Prin',\n",
    " 'Accomplished_TCHR_Standard 1_Pct',\n",
    " 'Accomplished_TCHR_Standard 2_Pct',\n",
    " 'Accomplished_TCHR_Standard 3_Pct',\n",
    " 'Accomplished_TCHR_Standard 4_Pct',\n",
    " 'Accomplished_TCHR_Standard 5_Pct',\n",
    " 'Developing_TCHR_Standard 1_Pct',\n",
    " 'Developing_TCHR_Standard 2_Pct',\n",
    " 'Developing_TCHR_Standard 3_Pct',\n",
    " 'Developing_TCHR_Standard 4_Pct',\n",
    " 'Developing_TCHR_Standard 5_Pct',\n",
    " 'Distinguished_TCHR_Standard 1_Pct',\n",
    " 'Distinguished_TCHR_Standard 2_Pct',\n",
    " 'Distinguished_TCHR_Standard 3_Pct',\n",
    " 'Distinguished_TCHR_Standard 4_Pct',\n",
    " 'Distinguished_TCHR_Standard 5_Pct',\n",
    " 'Not Demostrated_TCHR_Standard 1_Pct',\n",
    " 'Not Demostrated_TCHR_Standard 2_Pct',\n",
    " 'Not Demostrated_TCHR_Standard 3_Pct',\n",
    " 'Not Demostrated_TCHR_Standard 4_Pct',\n",
    " 'Not Demostrated_TCHR_Standard 5_Pct',\n",
    " 'Proficient_TCHR_Standard 1_Pct',\n",
    " 'Proficient_TCHR_Standard 2_Pct',\n",
    " 'Proficient_TCHR_Standard 3_Pct',\n",
    " 'Proficient_TCHR_Standard 4_Pct',\n",
    " 'Proficient_TCHR_Standard 5_Pct']\n",
    "\n",
    "fundingCols = ['lea_total_expense_num',\n",
    " 'lea_salary_expense_pct',\n",
    " 'lea_services_expense_pct',\n",
    " 'lea_supplies_expense_pct',\n",
    " 'lea_instruct_equip_exp_pct',\n",
    " 'lea_federal_perpupil_num',\n",
    " 'lea_local_perpupil_num',\n",
    " 'lea_state_perpupil_num']\n",
    "\n",
    "performCols = ['SPG Score',\n",
    " 'EVAAS Growth Score',\n",
    " 'Overall Achievement Score',\n",
    " 'TotalTargets_pTarget_PctMet',\n",
    " 'lea_sat_avg_score_num',\n",
    " 'lea_sat_participation_pct',\n",
    " 'lea_ap_participation_pct',\n",
    " 'lea_ap_pct_3_or_above',\n",
    " 'LPS_14',\n",
    " 'LPS_15',\n",
    " 'LPS_16',\n",
    " 'LPS_17',\n",
    " 'RLPS',\n",
    " 'SPG Grade_A+NG',\n",
    " 'SPG Grade_B',\n",
    " 'SPG Grade_C',\n",
    " 'SPG Grade_D',\n",
    " 'SPG Grade_F',\n",
    " 'SPG Grade_I',\n",
    " 'Reading SPG Grade_B',\n",
    " 'Reading SPG Grade_C',\n",
    " 'Reading SPG Grade_D',\n",
    " 'Reading SPG Grade_F',\n",
    " 'Math SPG Grade_B',\n",
    " 'Math SPG Grade_C',\n",
    " 'Math SPG Grade_D',\n",
    " 'Math SPG Grade_F',\n",
    " 'EVAAS Growth Status_Met',\n",
    " 'EVAAS Growth Status_NotMet',\n",
    " 'State Gap Compared_Y']\n",
    "\n",
    "featureImportance = ['student_num', 'class_teach_num', 'wap_num',\n",
    "                     'stud_internet_comp_num','avg_daily_attend_pct',\n",
    "                     'short_susp_per_c_num', 'lea_crime_per_c_num','flicensed_teach_pct', \n",
    "                     'nbpts_num', 'lea_advance_dgr_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cols = (environmentCols + fundingCols + educatorCols + profileCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(featureImportance)\n",
    "#print(combined_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cols.append('SPG Score')\n",
    "featureImportance.append('SPG Score')\n",
    "\n",
    "df_sub_14 = df_14[df_14.columns.intersection(combined_cols)]\n",
    "df_imp_14 = df_14[df_14.columns.intersection(featureImportance)]\n",
    "\n",
    "df_sub_15 = df_15[df_15.columns.intersection(combined_cols)]\n",
    "df_imp_15 = df_15[df_15.columns.intersection(featureImportance)]\n",
    "\n",
    "df_sub_16 = df_16[df_16.columns.intersection(combined_cols)]\n",
    "df_imp_16 = df_16[df_16.columns.intersection(featureImportance)]\n",
    "\n",
    "df_sub_17 = df_17[df_17.columns.intersection(combined_cols)]\n",
    "df_imp_17 = df_17[df_17.columns.intersection(featureImportance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check columns\n",
    "#df_sub_14.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combined Columns\n",
    "y_sub_14 = df_sub_14['SPG Score']\n",
    "x_sub_14 = df_sub_14.drop('SPG Score', axis=1)\n",
    "\n",
    "y_sub_15 = df_sub_15['SPG Score']\n",
    "x_sub_15 = df_sub_15.drop('SPG Score', axis=1)\n",
    "\n",
    "y_sub_16 = df_sub_16['SPG Score']\n",
    "x_sub_16 = df_sub_16.drop('SPG Score', axis=1)\n",
    "\n",
    "y_sub_17 = df_sub_17['SPG Score']\n",
    "x_sub_17 = df_sub_17.drop('SPG Score', axis=1)\n",
    "\n",
    "\n",
    "## Feature Importance\n",
    "y_imp_14 = df_imp_14['SPG Score']\n",
    "x_imp_14 = df_imp_14.drop('SPG Score', axis=1)\n",
    "\n",
    "y_imp_15 = df_imp_15['SPG Score']\n",
    "x_imp_15 = df_imp_15.drop('SPG Score', axis=1)\n",
    "\n",
    "y_imp_16 = df_imp_16['SPG Score']\n",
    "x_imp_16 = df_imp_16.drop('SPG Score', axis=1)\n",
    "\n",
    "y_imp_17 = df_imp_17['SPG Score']\n",
    "x_imp_17 = df_imp_17.drop('SPG Score', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# combined 2014 split\n",
    "X_sub_train14, X_sub_test14, y_sub_train14, y_sub_test14 = train_test_split(x_sub_14, y_sub_14, test_size=0.20, random_state=5)\n",
    "\n",
    "# combined 2015 split\n",
    "X_sub_train15, X_sub_test15, y_sub_train15, y_sub_test15 = train_test_split(x_sub_15, y_sub_15, test_size=0.20, random_state=5)\n",
    "\n",
    "# combined 2016 split\n",
    "X_sub_train16, X_sub_test16, y_sub_train16, y_sub_test16 = train_test_split(x_sub_16, y_sub_16, test_size=0.20, random_state=5)\n",
    "\n",
    "# combined 2017 split\n",
    "X_sub_train17, X_sub_test17, y_sub_train17, y_sub_test17 = train_test_split(x_sub_17, y_sub_17, test_size=0.20, random_state=5)\n",
    "\n",
    "# feat imp 2014 split\n",
    "X_imp_train14, X_imp_test14, y_imp_train14, y_imp_test14 = train_test_split(x_imp_14, y_imp_14, test_size=0.20, random_state=5)\n",
    "\n",
    "# feat imp 2015 split\n",
    "X_imp_train15, X_imp_test15, y_imp_train15, y_imp_test15 = train_test_split(x_imp_15, y_imp_15, test_size=0.20, random_state=5)\n",
    "\n",
    "# feat imp 2016 split\n",
    "X_imp_train16, X_imp_test16, y_imp_train16, y_imp_test16 = train_test_split(x_imp_16, y_imp_16, test_size=0.20, random_state=5)\n",
    "\n",
    "# feat imp 2017 split\n",
    "X_imp_train17, X_imp_test17, y_imp_train17, y_imp_test17 = train_test_split(x_imp_17, y_imp_17, test_size=0.20, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "def model_spg(train, trainTarg, test, testTarg):\n",
    "    model = XGBRegressor(nthread=4)\n",
    "    model.fit(train, trainTarg)\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    explained_variance = explained_variance_score(testTarg, predictions)\n",
    "    MAE = mean_absolute_error(testTarg, predictions)\n",
    "    MSE = mean_squared_error(testTarg, predictions)\n",
    "    rsq = r2_score(testTarg, predictions)\n",
    "    \n",
    "    print('MAE: ', MAE)\n",
    "    print('MSE: ', MSE)\n",
    "    print('R Squared: ', rsq)\n",
    "\n",
    "    return MAE, MSE, rsq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  7.38271604938\n",
      "MSE:  110.164609053\n",
      "R Squared:  0.687764576648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.382716049382716, 110.16460905349794, 0.68776457664784441)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2014\n",
    "model_spg(X_sub_train14, y_sub_train14, X_sub_test14, y_sub_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  6.40041067762\n",
      "MSE:  71.1765913758\n",
      "R Squared:  0.816847328451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.40041067761807, 71.176591375770016, 0.81684732845083341)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2015\n",
    "model_spg(X_sub_train15, y_sub_train15, X_sub_test15, y_sub_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  6.19135802469\n",
      "MSE:  62.524691358\n",
      "R Squared:  0.81699242425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.1913580246913584, 62.52469135802469, 0.8169924242496529)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2016\n",
    "model_spg(X_sub_train16, y_sub_train16, X_sub_test16, y_sub_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  6.0981595092\n",
      "MSE:  58.4785276074\n",
      "R Squared:  0.847532522582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.0981595092024543, 58.478527607361961, 0.8475325225820356)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2017\n",
    "model_spg(X_sub_train17, y_sub_train17, X_sub_test17, y_sub_test17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selected from XGBoost Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  8.31893004115\n",
      "MSE:  151.261316872\n",
      "R Squared:  0.571285717652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.3189300411522638, 151.26131687242798, 0.57128571765246516)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2014\n",
    "model_spg(X_imp_train14, y_imp_train14, X_imp_test14, y_imp_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  8.99383983573\n",
      "MSE:  180.854209446\n",
      "R Squared:  0.534623238053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.9938398357289522, 180.85420944558521, 0.53462323805312884)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2015\n",
    "model_spg(X_imp_train15, y_imp_train15, X_imp_test15, y_imp_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  8.05555555556\n",
      "MSE:  135.043209877\n",
      "R Squared:  0.604733267382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.0555555555555554, 135.04320987654322, 0.60473326738174127)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2016\n",
    "model_spg(X_imp_train16, y_imp_train16, X_imp_test16, y_imp_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  8.20654396728\n",
      "MSE:  151.773006135\n",
      "R Squared:  0.604291552262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.2065439672801634, 151.77300613496934, 0.60429155226153775)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2017\n",
    "model_spg(X_imp_train17, y_imp_train17, X_imp_test17, y_imp_test17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2443 entries, 0 to 2442\n",
      "Columns: 106 entries, title1_type_cd to SRC_devices_sent_home_Yes\n",
      "dtypes: float64(82), int64(24)\n",
      "memory usage: 2.0 MB\n",
      "None \n",
      "\n",
      "important: \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2443 entries, 0 to 2442\n",
      "Data columns (total 23 columns):\n",
      "summer_program_ind                  2443 non-null int64\n",
      "student_num                         2443 non-null float64\n",
      "avg_daily_attend_pct                2443 non-null float64\n",
      "crime_per_c_num                     2443 non-null float64\n",
      "short_susp_per_c_num                2443 non-null float64\n",
      "stud_internet_comp_num              2443 non-null float64\n",
      "lea_avg_daily_attend_pct            2443 non-null float64\n",
      "lea_crime_per_c_num                 2443 non-null float64\n",
      "lea_short_susp_per_c_num            2443 non-null float64\n",
      "lea_stud_internet_comp_num          2443 non-null float64\n",
      "wap_num                             2443 non-null float64\n",
      "wap_per_classroom                   2443 non-null float64\n",
      "flicensed_teach_pct                 2443 non-null float64\n",
      "tchyrs_0thru3_pct                   2443 non-null float64\n",
      "tchyrs_4thru10_pct                  2443 non-null float64\n",
      "class_teach_num                     2443 non-null float64\n",
      "nbpts_num                           2443 non-null float64\n",
      "advance_dgr_pct                     2443 non-null float64\n",
      "lea_tchyrs_4thru10_pct              2443 non-null float64\n",
      "lea_class_teach_num                 2443 non-null float64\n",
      "lea_advance_dgr_pct                 2443 non-null float64\n",
      "10+ Years_LEA_Exp_Pct_Prin          2443 non-null float64\n",
      "Accomplished_TCHR_Standard 1_Pct    2443 non-null float64\n",
      "dtypes: float64(22), int64(1)\n",
      "memory usage: 439.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create x explanatory and y response variables for regression\n",
    "GS_17 = df_17['SPG Score']\n",
    "unit_code = df_17['unit_code']\n",
    "\n",
    "X_combined = df_sub_17\n",
    "X_important = df_imp_17\n",
    "\n",
    "Y = GS_17\n",
    "\n",
    "#inspect data \n",
    "print('combined: \\n')\n",
    "print(X_combined.info(), '\\n')\n",
    "print('important: \\n')\n",
    "print(X_important.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "**Cross validation is performed using repeated holdout using ShuffleSplit()**\n",
    "* Ten folds are used\n",
    "* The split is: 90% training data and 10% test data\n",
    "* A random seed is set so the same random test and training splits are used each time cross validation is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Divide data into test and training splits\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Scorers for Evaluating Regression Models \n",
    "\n",
    "**All regression models created in this notebook are validated using the following metrics:**\n",
    "* Mean Absolute Error (MAE)\n",
    "* Root Mean Squared Error (RMSE) - https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "\n",
    "**For details on making scorers to return multiple mean error scores see:**\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "* https://github.com/scikit-learn/scikit-learn/pull/7388\n",
    "* https://github.com/drorata/multiscorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation\n",
    "** All regression models are evaluated using the regression model evaluation function below: ** \n",
    "* The following regression evaluation function uses the cross validation object and the custom scorers in the two cells above in combination with sklearn.model_selection's cross_validate function to perform cross validation for regression estimators.\n",
    "* The cross validation object above uses a random seed to ensure that all regression estimators are tested on the same randomly selected records for each cross validation fold.\n",
    "* Custom scorers are created using the three chosen mean error scores and passed into cross_validate(), so all three scores are calcualted using a single call to cross_validate().\n",
    "* All of this functionality is wrapped within the custom EvaluateRegressionEstimator() function below so multiple regression models may be tested using the same test / train cv data and evaluation scores producing a consistent output for each model without the need to re-write the same code over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 13.071\n",
      "The average RMSE for all cv folds is: \t\t\t 34.72\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.362843</td>\n",
       "      <td>17.424371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.052729</td>\n",
       "      <td>19.459643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.765161</td>\n",
       "      <td>18.740860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.026864</td>\n",
       "      <td>86.550308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.665364</td>\n",
       "      <td>19.737275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.981631</td>\n",
       "      <td>19.125772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.940998</td>\n",
       "      <td>66.841656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.797977</td>\n",
       "      <td>20.560340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.809147</td>\n",
       "      <td>60.163679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.306857</td>\n",
       "      <td>18.593574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAE       RMSE\n",
       "0  11.362843  17.424371\n",
       "1  12.052729  19.459643\n",
       "2  11.765161  18.740860\n",
       "3  17.026864  86.550308\n",
       "4  11.665364  19.737275\n",
       "5  11.981631  19.125772\n",
       "6  15.940998  66.841656\n",
       "7  12.797977  20.560340\n",
       "8  14.809147  60.163679\n",
       "9  11.306857  18.593574"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = SVR(C=0.01, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
    "                   kernel='linear', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_combined, Y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
