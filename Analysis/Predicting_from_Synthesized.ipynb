{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the Data\n",
    "\n",
    "** NOTE: I've removed any state-level columns as redundant, as well as explanatory variables we wouldn't want (eg. unit_code, school_name, etc) **\n",
    "\n",
    "** Some sets of variables still won't work when passing some sets of dataframes - they dont exist in all dataframes, and I'm not sure of a safe way to handle that **\n",
    "\n",
    "Can we include in the function a way to only synthesize data for public schools that are low performing? ie) don't increase the total_nbpts_num for *all* schools - only the ones that are low performing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# Loading data\n",
    "initial_path = '/Users/Olivia/SMUDS/Capstone/B/Github/Dataset Creation/'\n",
    "\n",
    "# 2014 Datasets\n",
    "df_elem_14 = pd.read_csv(initial_path+'2014/PublicElementarySchools2014_LPS_Processed.csv')\n",
    "df_mid_14 = pd.read_csv(initial_path+'2014/PublicMiddleSchools2014_LPS_Processed.csv')\n",
    "df_high_14 = pd.read_csv(initial_path+'2014/PublicHighSchools2014_LPS_Processed.csv')\n",
    "\n",
    "# 2015 Datasets\n",
    "df_elem_15 = pd.read_csv(initial_path+'2015/PublicElementarySchools2015_LPS_Processed.csv')\n",
    "df_mid_15 = pd.read_csv(initial_path+'2015/PublicMiddleSchools2015_LPS_Processed.csv')\n",
    "df_high_15 = pd.read_csv(initial_path+'2015/PublicHighSchools2015_LPS_Processed.csv')\n",
    "\n",
    "# 2016 Datasets\n",
    "df_elem_16 = pd.read_csv(initial_path+'2016/PublicElementarySchools2016_LPS_Processed.csv')\n",
    "df_mid_16 = pd.read_csv(initial_path+'2016/PublicMiddleSchools2016_LPS_Processed.csv')\n",
    "df_high_16 = pd.read_csv(initial_path+'2016/PublicHighSchools2016_LPS_Processed.csv')\n",
    "\n",
    "# 2017 Datasets\n",
    "df_elem_17 = pd.read_csv(initial_path+'2017/PublicElementarySchools2017_LPS_Processed.csv')\n",
    "df_mid_17 = pd.read_csv(initial_path+'2017/PublicMiddleSchools2017_LPS_Processed.csv')\n",
    "df_high_17 = pd.read_csv(initial_path+'2017/PublicHighSchools2017_LPS_Processed.csv')\n",
    "\n",
    "# Changing to LPS so it works the same across each dataset\n",
    "df_elem_17 = df_elem_17.rename(columns = {'LPS_17' : 'LPS'})\n",
    "df_mid_17 = df_mid_17.rename(columns = {'LPS_17' : 'LPS'})\n",
    "df_high_17 = df_high_17.rename(columns = {'LPS_17' : 'LPS'})\n",
    "\n",
    "'''\n",
    "# Loading in columns for different categories\n",
    "fileObject = open(initial path + '2014/TableColumns/environmentCols_14.pkl', 'rb')\n",
    "environment_cols = pickle.load(fileObject)\n",
    "\n",
    "fileObject = open(initial path + '2014/TableColumns/personnelCols_14.pkl', 'rb')\n",
    "personnel_cols = pickle.load(fileObject)\n",
    "\n",
    "fileObject = open(initial path + '2014/TableColumns/yoeCols_14.pkl', 'rb')\n",
    "yoe_cols = pickle.load(fileObject)\n",
    "\n",
    "# Full list of columns, including Personnel, Environment, and Teacher Experience Variables\n",
    "combined_cols = (environment_cols + list(set(personnel_cols) - set(environment_cols)))\n",
    "yoe_cols = ['0-3 Years_Exp_Pct_Tch',\n",
    "            '10+ Years_Exp_Pct_Tch',\n",
    "            '4-10 Years_Exp_Pct_Tch',\n",
    "            '0-3 Years_LEA_Exp_Pct_Prin',\n",
    "            '10+ Years_LEA_Exp_Pct_Prin',\n",
    "            '4-10 Years_LEA_Exp_Pct_Prin']\n",
    "for col in yoe_cols:\n",
    "    combined_cols.append(col)\n",
    "combined_cols.append('LPS')\n",
    "'''\n",
    "\n",
    "# So that you don't have to load the pickle objects \n",
    "#   for yoe_cols, environment_cols, and personnel_cols:\n",
    "yoe_cols = ['0-3 Years_Exp_Pct_Tch',\n",
    "            '10+ Years_Exp_Pct_Tch',\n",
    "            '4-10 Years_Exp_Pct_Tch',\n",
    "            '0-3 Years_LEA_Exp_Pct_Prin',\n",
    "            '10+ Years_LEA_Exp_Pct_Prin',\n",
    "            '4-10 Years_LEA_Exp_Pct_Prin']\n",
    "\n",
    "environment_cols = [\n",
    "                 'avg_daily_attend_pct',\n",
    "                 'crime_per_c_num',\n",
    "                 'short_susp_per_c_num',\n",
    "                 'long_susp_per_c_num',\n",
    "                 'expelled_per_c_num',\n",
    "                 'ttl_crimes_num',\n",
    "                 'stud_internet_comp_num',\n",
    "                 'lea_avg_daily_attend_pct',\n",
    "                 'lea_crime_per_c_num',\n",
    "                 'lea_short_susp_per_c_num',\n",
    "                 'lea_long_susp_per_c_num',\n",
    "                 'lea_expelled_per_c_num',\n",
    "                 'lea_stud_internet_comp_num',\n",
    "                 'digital_media_pct',\n",
    "                 'Byod',\n",
    "                 'grades_BYOD',\n",
    "                 'avg_age_media_collection',\n",
    "                 '_1_to_1_access',\n",
    "                 'books_per_student',\n",
    "                 'grades_1_to_1_access',\n",
    "                 'lea_avg_age_media_collection',\n",
    "                 'lea_books_per_student',\n",
    "                 'wap_num',\n",
    "                 'wap_per_classroom',\n",
    "                 'lea_wap_num',\n",
    "                 'lea_wap_per_classroom',\n",
    "                 'SRC_devices_sent_home',\n",
    "                 'SRC_Grades_Devices_Sent_Home']\n",
    "\n",
    "personnel_cols = ['total_class_teacher_num',\n",
    "                 'total_nbpts_num',\n",
    "                 'prin_other_pct',\n",
    "                 'prinyrs_0thru3_pct',\n",
    "                 'prinyrs_4thru10_pct',\n",
    "                 'prinyrs_11plus_pct',\n",
    "                 'prin_advance_dgr_pct',\n",
    "                 '_1yr_prin_trnovr_pct',\n",
    "                 'prin_male_pct',\n",
    "                 'prin_female_pct',\n",
    "                 'prin_black_pct',\n",
    "                 'prin_white_pct',\n",
    "                 'flicensed_teach_pct',\n",
    "                 'tchyrs_0thru3_pct',\n",
    "                 'tchyrs_4thru10_pct',\n",
    "                 'tchyrs_11plus_pct',\n",
    "                 'class_teach_num',\n",
    "                 'nbpts_num',\n",
    "                 'advance_dgr_pct',\n",
    "                 '_1yr_tchr_trnovr_pct',\n",
    "                 'emer_prov_teach_pct',\n",
    "                 'lateral_teach_pct',\n",
    "                 'highqual_class_pct',\n",
    "                 'lea_flicensed_teach_pct',\n",
    "                 'lea_tchyrs_0thru3_pct',\n",
    "                 'lea_tchyrs_4thru10_pct',\n",
    "                 'lea_tchyrs_11plus_pct',\n",
    "                 'lea_class_teach_num',\n",
    "                 'lea_nbpts_num',\n",
    "                 'lea_advance_dgr_pct',\n",
    "                 'lea_1yr_tchr_trnovr_pct',\n",
    "                 'lea_emer_prov_teach_pct',\n",
    "                 'lea_lateral_teach_pct',\n",
    "                 'lea_highqual_class_pct',\n",
    "                 'lea_highqual_class_hp_pct',\n",
    "                 'lea_highqual_class_lp_pct',\n",
    "                 'lea_highqual_class_all_pct',\n",
    "                 'lea_not_highqual_class_hp_pct',\n",
    "                 'lea_not_highqual_class_lp_pct',\n",
    "                 'lea_not_highqual_class_all_pct']\n",
    "\n",
    "\n",
    "'''\n",
    "# Subsets each dataframe based on the columns it shares with the \n",
    "# three sets of variables found in \"combined_cols\" (environment, personnel, and yoe)\n",
    "\n",
    "df_elem_14 = df_elem_14[df_elem_14.columns.intersection(combined_cols)]\n",
    "df_mid_14 = df_mid_14[df_mid_14.columns.intersection(combined_cols)]\n",
    "df_high_14 = df_high_14[df_high_14.columns.intersection(combined_cols)]\n",
    "df_elem_15 = df_elem_15[df_elem_15.columns.intersection(combined_cols)]\n",
    "df_mid_15 = df_mid_15[df_mid_15.columns.intersection(combined_cols)]\n",
    "df_high_15 = df_high_15[df_high_15.columns.intersection(combined_cols)]\n",
    "df_elem_16 = df_elem_16[df_elem_16.columns.intersection(combined_cols)]\n",
    "df_mid_16 = df_mid_16[df_mid_16.columns.intersection(combined_cols)]\n",
    "df_high_16 = df_high_16[df_high_16.columns.intersection(combined_cols)]\n",
    "df_elem_17 = df_elem_17[df_elem_17.columns.intersection(combined_cols)]\n",
    "df_mid_17 = df_mid_17[df_mid_17.columns.intersection(combined_cols)]\n",
    "df_high_17 = df_high_17[df_high_17.columns.intersection(combined_cols)]\n",
    "'''\n",
    "\n",
    "# Setting names for dfs to be referenced in column names later\n",
    "df_elem_14.name = 'df_elem_14'\n",
    "df_mid_14.name = 'df_mid_14'\n",
    "df_high_14.name = 'df_high_14' \n",
    "df_elem_15.name = 'df_elem_15'\n",
    "df_mid_15.name = 'df_mid_15'\n",
    "df_high_15.name = 'df_high_15'\n",
    "df_elem_16.name = 'df_elem_16'\n",
    "df_mid_16.name = 'df_mid_16'\n",
    "df_high_16.name = 'df_high_16'\n",
    "df_elem_17.name = 'df_elem_17'\n",
    "df_mid_17.name = 'df_mid_17'\n",
    "df_high_17.name = 'df_high_17'\n",
    "\n",
    "# Storing dfs in list for later iteration\n",
    "all_datasets = [df_elem_14, df_mid_14, df_high_14,\n",
    "                df_elem_15, df_mid_15, df_high_15,\n",
    "                df_elem_16, df_mid_16, df_high_16,\n",
    "                df_elem_17, df_mid_17, df_high_17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "'crystal_ball()' is the primary function. Given a set of 'train_dfs' (dataframes used in training/predicting - argument can be used to subset only elementary, middle, or high schools, or only specific years, for example) along with explanatory and target variables, it will:\n",
    "\n",
    "1. Train the model on the original data.\n",
    "2. Use the synthesize_data() function to increase/decrease certain variables according the pre-specificed \"synthetic_specs\" dictionary.\n",
    "3. Use the new synthesized data to make a new prediction of the target variable.\n",
    "4. The differences between the original target variables and the new predicted target variables (from synthesized data) are logged in a dataframe called 'all_changes'.\n",
    "5. Arguments can specify whether to return the 'all_changes' dataframe (for a closer look) or can choose to simply return the average of the dataframe. \n",
    "\n",
    "\n",
    "Argument options can be found in the docstring, but here's a brief description:\n",
    "\n",
    "        train_dfs: list of datasets to be used for training the model\n",
    "        synthetic_specs: dictionary which specifies the variables to\n",
    "                          be synthesized, and by how much.\n",
    "        target_variable: the variable to be predicted \n",
    "        binarize_target: if True, the continuous target variable will be \n",
    "                            set to 0 if it is below average, or 1 for above avg.\n",
    "        explanatory_variables: set of variables to be used in predicting target variables\n",
    "                                eg. 'environment_vars' or 'yoe_vars'\n",
    "        model: type of model to be used in predicting\n",
    "        return_type: can choose to return a 'dataframe' of differences between\n",
    "                        predicted future values (based on synthetic data) and the original\n",
    "                        value in the training dataframe.\n",
    "                    OR can return the average of that entire dataframe\n",
    "\n",
    "\n",
    "By choosing to return the average of the entire dataframe, we can iterate through different sets of parameters (increases/decreases to certain variables) to get the most ideal corresponding increase/decrease to certain target variables\n",
    "\n",
    "A few notes:\n",
    "1. Not all columns are shared among all dataframes...currently working on how to handle this within the function itself.\n",
    "2. Some of the original dataframes are of different lengths, meaning that when the 'all_changes' dataframe is calculated, there is potential for there to be NaNs. Shouldn't cause any issues, but be aware.\n",
    "3. More sklearn model could be added by playing with the conditional statements in the function body.\n",
    "    Eg: *(if model == 'anyothermodel': regr = AnyOtherModel())*\n",
    "4. Should probably play with model arguments, I haven't so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This, for example would synthetically increase 'lea_total_expense_num' by 10%,\n",
    "# and would decrease 'lea_salary_expense_pct' by 20%\n",
    "synthetic_specs = {'lea_total_expense_num' : 1.1,\n",
    "                   'lea_salary_expense_pct' : 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthesize_data(df, synthetic_specs = synthetic_specs):\n",
    "    '''Takes a dataframe as input, alters the \n",
    "    synthetic variables by the specified factor'''\n",
    "    \n",
    "    future_data = df.copy()\n",
    "    for k,v in synthetic_specs.items():\n",
    "        future_data[k] = df[k] * v\n",
    "        \n",
    "    return future_data\n",
    "\n",
    "\n",
    "def crystal_ball(train_dfs = all_datasets, \n",
    "                 synthetic_specs = synthetic_specs, \n",
    "                 target_variable = 'LPS',\n",
    "                 binarize_target = False,\n",
    "                 explanatory_variables = yoe_cols,\n",
    "                 model = 'random_forest',\n",
    "                 return_type = 'dataframe'): \n",
    "    '''\n",
    "    Predicts the future...duh\n",
    "    \n",
    "    Argument Options:\n",
    "        train_dfs: any set of dataframes, eg. [df_elem_14, df_elem_15, df_elem_16, df_high_17]\n",
    "        synthetic_specs: pre-specified dictionary of variables to change, and by how much\n",
    "        target_variable: any target variable\n",
    "        binarize_target: True/False\n",
    "        explanatory_variables: any list of variables (make sure they exist in every df in train_dfs) \n",
    "        model: 'random_forest' or 'adaboost', more to be added\n",
    "        return_type: 'dataframe' or 'avg'\n",
    "        \n",
    "    '''\n",
    "\n",
    "    # Raise a warning if trying to synthesize a variable that will have no effect on target\n",
    "    for k in list(synthetic_specs):\n",
    "        if k not in explanatory_variables:\n",
    "            warnings.warn('''There are variables included in synthetic_specs which are not included\n",
    "                          in explanatory_variables. Ie. You are attempting to make changes to \n",
    "                          variables which are not being included in the models' predictions. See below''')\n",
    "            print(str(k) + ' is not an explanatory_variable')\n",
    "    \n",
    "    # Select which type of algorithm to fit/train\n",
    "    if model == 'random_forest':\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        regr = RandomForestRegressor(random_state=0)\n",
    "    if model == 'adaboost':\n",
    "        from sklearn.ensemble import AdaBoostRegressor\n",
    "        regr = AdaBoostRegressor(random_state=0)\n",
    "    # if model == 'anyothermodel':\n",
    "    #   from sklearn import AnyOtherModel\n",
    "    #   regr = AnyOtherModel(random_state=0)\n",
    "        \n",
    "    \n",
    "    # Empty dataframe for appending changes to target variables\n",
    "    all_changes = pd.DataFrame()\n",
    "        \n",
    "    # Train model on given datasets, predict target variable on equivalent synthesized df:\n",
    "    for df in train_dfs:\n",
    "        # Use current df to synthesize data according to synthetic_specs\n",
    "        future_data = synthesize_data(df, synthetic_specs=synthetic_specs)\n",
    "\n",
    "        # x, y variables for training\n",
    "        y = df[target_variable]\n",
    "        x = df[explanatory_variables]\n",
    "\n",
    "        if binarize_target:\n",
    "            y = [1 if value > y.mean() else 0 for value in y.values]\n",
    "\n",
    "        # Fit/predict model\n",
    "        #regr = RandomForestRegressor(random_state=0)\n",
    "        regr.fit(x, y)\n",
    "        future_predictions = regr.predict(future_data[explanatory_variables])\n",
    "\n",
    "        # Calculate changes between future_predicted and original values of target variable\n",
    "        target_var_changes = y - future_predictions\n",
    "\n",
    "        # Append as a column to \"all_changes\" dataframe\"\n",
    "        all_changes[df.name + '_' + target_variable +'_changes'] = target_var_changes\n",
    "            \n",
    "            \n",
    "    if return_type == 'dataframe':    \n",
    "        # Returns the dataframe of each datasets change for each predicted y-value\n",
    "        return all_changes\n",
    "    elif return_type == 'avg':\n",
    "        # returns single average change across all datasets, ignoring NaNs\n",
    "        return np.nanmean(all_changes.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Usage\n",
    "\n",
    "In the below example, we choose to artificially increase '0-3 Years_Exp_Pct_Tch' by 50%, and to decrease '10+ Years_Exp_Pct_Tch' by 30% (as specified in synthetic_specs). Our function returns that this change, on average made a -15.6% difference in the target variable 'LPS'.\n",
    "\n",
    "**NOTE** that even though the target variable 'LPS' is a binary variable originally, the selected random forest model is a regressor, so will make predictions in the continuous range(0,1). This is a good thing, because we can use binary target variables and still compare by how much different levels of synthesized data change predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1342251938827281"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_specs = {'0-3 Years_Exp_Pct_Tch' : 1.5, # Every instance of this variable is multiplied by 1.5\n",
    "                   '10+ Years_Exp_Pct_Tch' : 0.7} # Every instance multiplied by 0.7\n",
    "\n",
    "crystal_ball(train_dfs = all_datasets,\n",
    "             synthetic_specs = synthetic_specs, \n",
    "             target_variable = 'LPS',\n",
    "             binarize_target = False,\n",
    "             explanatory_variables = yoe_cols,\n",
    "             model = 'random_forest',\n",
    "             return_type = 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the warning\n",
    "\n",
    "A warning will be raised if there is a variable in 'synthetic_specs' which does not get used as an explanatory variable in the model. It will have no effect on the model's predictions, so its good to know that although we did synthesize data regarding this variable, it did not get included in predictions.\n",
    "\n",
    "We can test this by looking at a model which \"accidentally\" does not synthesize any data which are included as explanatory_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_bea\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: There are variables included in synthetic_specs which are not included\n",
      "                          in explanatory_variables. Ie. You are attempting to make changes to \n",
      "                          variables which are not being included in the models' predictions. See below\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lea_crime_per_c_num is not an explanatory_variable\n",
      "lea_tchyrs_11plus_pct is not an explanatory_variable\n",
      "lea_long_susp_per_c_num is not an explanatory_variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0061216206421685895"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NONE OF THESE VARIABLES ARE IN yoe_cols (which are passed to crystal_ball())\n",
    "synthetic_specs = {'lea_crime_per_c_num' : 1.5,\n",
    "                   'lea_tchyrs_11plus_pct' : 0.9,\n",
    "                   'lea_long_susp_per_c_num' : 100000}\n",
    "\n",
    "crystal_ball(train_dfs = all_datasets,\n",
    "             synthetic_specs = synthetic_specs, \n",
    "             target_variable = 'LPS',\n",
    "             binarize_target = False,\n",
    "             explanatory_variables = yoe_cols, # We pass yoe_cols, none of which have been synthesized\n",
    "             model = 'random_forest',\n",
    "             return_type = 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! The average difference in the prediction on \"synthesized\" data is very minor (-0.006), proving both that the synthesized variables in synthetic_specs were not used in the model, AND also that our model is fairly accurate! \n",
    "\n",
    "** Synthesizing variables which are not used in the model (not passed to crystal_ball() as explanatory variables) succesfully raises a warning, and can even be used to test model accuracy) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other example usage\n",
    "\n",
    "The next example shows a limited set of environment_cols (had errors trying to use the full set due to some columns not appearing in all of the dataframes), with different options.\n",
    "\n",
    "Although adaboost can't be directly interpreted, by synthesizing data we can say that changing each of the variables in 'synthetic_specs' by their associated factors leads to a 4.48 increase in the target variable, 'EVAAS Growth Score' (except of course 'lea_tchyrs_11plus_pct', which is properly identified as having not been used in the model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limited_environment_cols = ['avg_daily_attend_pct',\n",
    " 'crime_per_c_num',\n",
    " 'short_susp_per_c_num',\n",
    " 'long_susp_per_c_num',\n",
    " 'expelled_per_c_num',\n",
    " 'stud_internet_comp_num',\n",
    " 'lea_avg_daily_attend_pct',\n",
    " 'lea_crime_per_c_num',\n",
    " 'lea_short_susp_per_c_num',\n",
    " 'lea_long_susp_per_c_num',\n",
    " 'lea_expelled_per_c_num',\n",
    " 'lea_stud_internet_comp_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k_bea\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: There are variables included in synthetic_specs which are not included\n",
      "                          in explanatory_variables. Ie. You are attempting to make changes to \n",
      "                          variables which are not being included in the models' predictions. See below\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lea_tchyrs_11plus_pct is not an explanatory_variable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.628325468521985"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens when we increase certain environment variables?\n",
    "synthetic_specs = {'avg_daily_attend_pct' : 1.8,\n",
    "                   'expelled_per_c_num' : 0.5,\n",
    "                   'long_susp_per_c_num' : 0.6,\n",
    "                   'lea_crime_per_c_num' : 0.03,\n",
    "                   'lea_tchyrs_11plus_pct' : 0.1}\n",
    "\n",
    "high_schools_only = [df_high_14, df_high_15, df_high_16, df_high_17]\n",
    "\n",
    "crystal_ball(train_dfs = high_schools_only,\n",
    "             synthetic_specs = synthetic_specs, \n",
    "             target_variable = 'EVAAS Growth Score',\n",
    "             binarize_target = False,\n",
    "             explanatory_variables = limited_environment_cols,\n",
    "             model = 'adaboost',\n",
    "             return_type = 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Usage\n",
    "\n",
    "Iterating over different levels of factors could show us how much increase/decrease in each explanatory variable could maximize/minimize a given target variable. So say we want to see which teacher variables lead to the best increases in EVAAS growth score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-3 Years_Exp_Pct_Tch',\n",
       " '10+ Years_Exp_Pct_Tch',\n",
       " '4-10 Years_Exp_Pct_Tch',\n",
       " '0-3 Years_LEA_Exp_Pct_Prin',\n",
       " '10+ Years_LEA_Exp_Pct_Prin',\n",
       " '4-10 Years_LEA_Exp_Pct_Prin']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoe_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increase to Explanatory Variable: 1.05\n",
      "Associated change to EVAAS Growth Score: 1.1726173654875\n",
      "--\n",
      "\n",
      "Increase to Explanatory Variable: 1.06\n",
      "Associated change to EVAAS Growth Score: 1.1630270417163049\n",
      "--\n",
      "\n",
      "Increase to Explanatory Variable: 1.07\n",
      "Associated change to EVAAS Growth Score: 1.1766992035164872\n",
      "--\n",
      "\n",
      "Increase to Explanatory Variable: 1.1\n",
      "Associated change to EVAAS Growth Score: 1.1862375866897974\n",
      "--\n",
      "\n",
      "Increase to Explanatory Variable: 1.2\n",
      "Associated change to EVAAS Growth Score: 1.1603828824284144\n",
      "--\n",
      "\n",
      "Increase to Explanatory Variable: 1.9\n",
      "Associated change to EVAAS Growth Score: 1.118647178965067\n",
      "--\n",
      "\n"
     ]
    }
   ],
   "source": [
    "factors = [1.05, 1.06, 1.07, 1.1, 1.2, 1.9]\n",
    "results = []\n",
    "for factor in factors:\n",
    "    synthetic_specs = {'0-3 Years_Exp_Pct_Tch' : factor}\n",
    "    \n",
    "    \n",
    "    result = crystal_ball(train_dfs = high_schools_only,\n",
    "             synthetic_specs = synthetic_specs, \n",
    "             target_variable = 'EVAAS Growth Score',\n",
    "             binarize_target = False,\n",
    "             explanatory_variables = yoe_cols,\n",
    "             model = 'adaboost',\n",
    "             return_type = 'avg')\n",
    "    \n",
    "    results.append(result)\n",
    "    \n",
    "    print('Increase to Explanatory Variable:', factor)\n",
    "    print('Associated change to EVAAS Growth Score:', result)\n",
    "    print('--\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1e7e3114dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAELCAYAAADKjLEqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxnjFEoYxxhiv/H8lJzDrAZHAxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e7e3555048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(factors, results)\n",
    "plt.xlabel('Factor change to 0-3 Years_Exp_Pct_Tch')\n",
    "plt.ylabel('Factor change to EVAAS Growth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Could use a similar process to iterate over different factor levels, but also over different models, and then averaging their results as an ensemble **\n",
    "\n",
    "eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-c424e6b3baf3>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-c424e6b3baf3>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    etc etc\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for model in ['adaboost', 'random_forest']:\n",
    "    etc etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
