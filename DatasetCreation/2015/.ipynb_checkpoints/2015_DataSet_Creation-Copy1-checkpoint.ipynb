{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 2014-2015 School Datasets\n",
    "** This program uses all raw datasets to create the flattened datasets within the NCEA repository.**\n",
    "1. This notebook reads raw dataset .csv files directly from the \\EducationDataNC\\2015\\Raw Datasets folder.\n",
    "2. Each raw dataset is transformed to contain only one record per public school campus or unique unit_code.\n",
    "3. Many raw datasets have more than one record per campus, per year.  In these instances, table pivots are used to create new columns from row level entries and reduce each dataset to one record per school.  This adds many new colums the flattened dataset.  (see the code below for more details) \n",
    "\n",
    "4. Column names for each table are saved separatley in .pkl files for later subsetting.\n",
    "5. Datasets for **all** public/charter schools, and public/charter **High schools** and public/charter **Middle schools** and public/charter and **Elementary schools** will result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Olivia/SMUDS/Capstone/B/GitHub/Dataset Creation/2015/\n"
     ]
    }
   ],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#All raw data files are processed for the year below\n",
    "schoolYear = 2015\n",
    "\n",
    "#Location where copies of the raw data files will be read in from csv files.\n",
    "dataDir = 'https://raw.githubusercontent.com/jakemdrew/EducationDataNC/master/2015/Raw%20Datasets/'\n",
    "\n",
    "#Location where the new school datasets will be created.\n",
    "cwd = os.getcwd()\n",
    "outputDir = cwd + '/'\n",
    "\n",
    "tcd = outputDir+'TableColumns'\n",
    "if not os.path.exists(tcd):\n",
    "    os.makedirs(tcd)\n",
    "tcd = tcd + '/'\n",
    "\n",
    "print (outputDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Raw Data Files\n",
    "**This section reads raw data files directly from the \\EducationDataNC\\ *schoolYear* \\Raw Datasets folder.**  \n",
    "* The file input location is specified at the *dataDir* parameter.\n",
    "* The file output location is specified at the *outputDir* parameter.\n",
    "* The *schoolYear* parameter is used to specify the correct school year to process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: READY ACC Drilldown and Read To Achieve Tables are not Included in Final Dataset, but are saved as separate tables in case later inclusion is necessary**\n",
    "\n",
    "*ACC Drilldown Columns:* {'District Name', 'unit_code', 'School Name', 'SBE Region', 'Subject',\n",
    "       'Standard (CCR - Level 4 & 5, GLP - Level 3 & Above)', 'All Students',\n",
    "       'Female', 'Male', 'American Indian', 'Asian', 'Black', 'Hispanic',\n",
    "       'Two or More Races', 'White', 'EDS', 'LEP', 'SWD', 'AIG',\n",
    "       'All Students_Ct', 'Female_Ct', 'Male.1', 'American Indian_Ct',\n",
    "       'Asian_Ct', 'Black_Ct', 'Hispanic_Ct', 'Two or More Races_Ct',\n",
    "       'White.1', 'EDS_Ct', 'LEP_Ct', 'SWD_Ct', 'AIG_Ct'}\n",
    "\n",
    "*RTA Columns:* {'metrics', 'year', 'unit_code', 'Lea_Name', 'School_Name', 'State_Name',\n",
    "       'category_cd', 'pct', 'num', 'lea_num', 'lea_pct', 'st_num', 'st_pct'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vphone_ad', 'year', 'unit_code', 'street_ad', 'scity_ad', 'state_ad', 'szip_ad', 'type_cd', 'closed_ind', 'new_ind', 'super_nm', 'category_cd', 'url_ad', 'grade_range_cd', 'calendar_type_txt', 'sna_pgm_type_cd', 'cover_letter_ad', 'school_type_txt', 'calendar_only_txt', 'title1_type_cd', 'clp_ind', 'focus_clp_ind', 'summer_program_ind', 'asm_no_spg_ind', 'no_data_spg_ind', 'Lea_Name', 'School_Name', 'State_Name', 'esea_status', 'student_num', 'lea_avg_student_num', 'st_avg_student_num', 'Grad_project_status', 'stem', 'url']\n",
      "['year', 'unit_code', 'Lea_Name', 'School_Name', 'State_Name', 'category_cd', 'total_expense_num', 'salary_expense_pct', 'benefits_expense_pct', 'services_expense_pct', 'supplies_expense_pct', 'instruct_equip_exp_pct', 'other_expense_pct', 'federal_perpupil_num', 'local_perpupil_num', 'state_perpupil_num', 'lea_total_expense_num', 'lea_salary_expense_pct', 'lea_benefits_expense_pct', 'lea_services_expense_pct', 'lea_supplies_expense_pct', 'lea_instruct_equip_exp_pct', 'lea_other_expense_pct', 'lea_federal_perpupil_num', 'lea_local_perpupil_num', 'lea_state_perpupil_num', 'st_total_expense_num', 'st_salary_expense_pct', 'st_benefits_expense_pct', 'st_services_expense_pct', 'st_supplies_expense_pct', 'st_instruct_equip_exp_pct', 'st_other_expense_pct', 'st_federal_perpupil_num', 'st_local_perpupil_num', 'st_state_perpupil_num', 'building_expense_pct', 'lea_building_expense_pct', 'st_building_expense_pct']\n",
      "['LEA Name', 'unit_code', 'School Name', 'SBE District', 'SPG Grade', 'SPG Score', 'Reading SPG Grade', 'Reading  SPG Score', 'Math SPG Grade', 'Math SPG Score', 'EVAAS Growth Status', 'EVAAS Growth Score', 'Overall Achievement Score', 'Read Score', 'Math Score', 'Science Score', 'Math I Score', 'English II Score', 'Biology Score', 'The ACT Score', 'ACT WorkKeys Score', 'Math Course Rigor Score', 'Cohort Graduation Rate Standard Score', 'State Gap Compared']\n",
      "['year', 'unit_code', 'School_Name', 'Lea_Name', 'State_Name', 'Category_Cd', 'sat_avg_score_num', 'lea_sat_avg_score_num', 'st_sat_avg_score_num', 'nat_sat_avg_score_num', 'sat_participation_pct', 'lea_sat_participation_pct', 'st_sat_participation_pct', 'nat_sat_participation_pct', 'esea_attendance', 'lea_esea_attendance', 'ap_participation_pct', 'lea_ap_participation_pct', 'st_ap_participation_pct', 'ap_pct_3_or_above', 'lea_ap_pct_3_or_above', 'st_ap_pct_3_or_above', 'ib_participation_pct', 'lea_ib_participation_pct', 'st_ib_participation_pct', 'ib_pct_4_or_above', 'lea_ib_pct_4_or_above', 'st_ib_pct_4_or_above']\n",
      "['year', 'unit_code', 'category_cd', 'School_Name', 'Lea_Name', 'State_Name', 'total_specialized_courses', 'ap_ib_courses', 'cte_courses', 'univ_college_courses', 'lea_total_specialized_courses', 'lea_ap_ib_courses', 'lea_cte_courses', 'lea_univ_college_courses', 'st_total_specialized_courses', 'st_ap_ib_courses', 'st_cte_courses', 'st_univ_college_courses']\n",
      "['graduation_year', 'unit_code', 'leaname', 'schname', 'status', 'subgroup', 'subgroup_name', 'schcount', 'leacount', 'seacount', 'sch_percent_enrolled', 'lea_percent_enrolled', 'sea_percent_enrolled']\n",
      "['year', 'unit_code', 'category_cd', 'Lea_Name', 'School_Name', 'State_Name', 'avg_daily_attend_pct', 'crime_per_c_num', 'short_susp_per_c_num', 'long_susp_per_c_num', 'expelled_per_c_num', 'ttl_crimes_num', 'stud_internet_comp_num', 'lea_avg_daily_attend_pct', 'lea_crime_per_c_num', 'lea_short_susp_per_c_num', 'lea_long_susp_per_c_num', 'lea_expelled_per_c_num', 'lea_stud_internet_comp_num', 'st_avg_daily_attend_pct', 'st_crime_per_c_num', 'st_short_susp_per_c_num', 'st_long_susp_per_c_num', 'st_expelled_per_c_num', 'st_stud_internet_comp_num', 'digital_media_pct', 'Byod', 'grades_BYOD', 'avg_age_media_collection', '_1_to_1_access', 'books_per_student', 'grades_1_to_1_access', 'lea_avg_age_media_collection', 'lea_books_per_student', 'st_avg_age_media_collection', 'st_books_per_student', 'wap_num', 'wap_per_classroom', 'lea_wap_num', 'lea_wap_per_classroom', 'st_wap_num', 'st_wap_per_classroom', 'SRC_devices_sent_home', 'SRC_Grades_Devices_Sent_Home']\n",
      "['year', 'unit_code', 'category_cd', 'total_class_teacher_num', 'total_nbpts_num', 'prin_other_pct', 'prinyrs_0thru3_pct', 'prinyrs_4thru10_pct', 'prinyrs_11plus_pct', 'prin_advance_dgr_pct', '_1yr_prin_trnovr_pct', 'prin_male_pct', 'prin_female_pct', 'prin_black_pct', 'prin_white_pct', 'School_Name', 'Lea_Name', 'State_Name', 'flicensed_teach_pct', 'tchyrs_0thru3_pct', 'tchyrs_4thru10_pct', 'tchyrs_11plus_pct', 'class_teach_num', 'nbpts_num', 'advance_dgr_pct', '_1yr_tchr_trnovr_pct', 'emer_prov_teach_pct', 'lateral_teach_pct', 'highqual_class_pct', 'lea_flicensed_teach_pct', 'lea_tchyrs_0thru3_pct', 'lea_tchyrs_4thru10_pct', 'lea_tchyrs_11plus_pct', 'lea_class_teach_num', 'lea_nbpts_num', 'lea_advance_dgr_pct', 'lea_1yr_tchr_trnovr_pct', 'lea_emer_prov_teach_pct', 'lea_lateral_teach_pct', 'lea_highqual_class_pct', 'lea_highqual_class_hp_pct', 'lea_highqual_class_lp_pct', 'lea_highqual_class_all_pct', 'lea_not_highqual_class_hp_pct', 'lea_not_highqual_class_lp_pct', 'lea_not_highqual_class_all_pct', 'st_flicensed_teach_pct', 'st_tchyrs_0thru3_pct', 'st_tchyrs_4thru10_pct', 'st_tchyrs_11plus_pct', 'st_class_teach_num', 'st_nbpts_num', 'st_advance_dgr_pct', 'st_1yr_tchr_trnovr_pct', 'st_emer_prov_teach_pct', 'st_lateral_teach_pct', 'st_highqual_class_pct', 'st_highqual_class_hp_pct', 'st_highqual_class_lp_pct', 'st_highqual_class_all_pct', 'st_not_highqual_class_hp_pct', 'st_not_highqual_class_lp_pct', 'st_not_highqual_class_all_pct', 'st_prinyrs_0thru3_pct', 'st_prinyrs_4thru10_pct', 'st_prinyrs_11plus_pct', 'st_prin_advance_dgr_pct', 'st_1yr_prin_trnovr_pct', 'st_prin_male_pct', 'st_prin_female_pct', 'st_prin_black_pct', 'st_prin_white_pct', 'st_prin_other_pct']\n"
     ]
    }
   ],
   "source": [
    "#Read in raw data files\n",
    "\n",
    "#Profile Table \n",
    "profile = pd.read_csv(dataDir + 'profile.csv', low_memory=False, dtype={'unit_code': object})\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "profileCols = list(profile.columns)\n",
    "f = open(tcd + \"profileCols_15.pkl\",\"wb\")\n",
    "pickle.dump(profileCols,f)\n",
    "f.close()\n",
    "print (profileCols)\n",
    "\n",
    "#Profile Metric Table \n",
    "profileMetric = pd.read_csv(dataDir + 'profile-metrics.csv', low_memory=False, dtype={'unit_code': object})\n",
    "\n",
    "#Funding Table\n",
    "funding = pd.read_csv(dataDir + 'funding.csv', low_memory=False, dtype={'unit_code': object})                     \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "fundingCols = list(funding.columns)\n",
    "f = open(tcd + \"fundingCols_15.pkl\",\"wb\")\n",
    "pickle.dump(fundingCols,f)\n",
    "f.close()\n",
    "print (fundingCols)\n",
    "\n",
    "#School Performance Grade (SPG) Table\n",
    "spg = pd.read_csv(dataDir + 'spg.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "spgCols = list(spg.columns)\n",
    "f = open(tcd + \"spgCols_15.pkl\",\"wb\")\n",
    "pickle.dump(spgCols,f)\n",
    "f.close()\n",
    "print (spgCols)\n",
    "\n",
    "#READY Accountability Drill Down\n",
    "accDrillDown = pd.read_csv(dataDir + 'accDrillDown.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "# #Read To Achieve (RTA) \n",
    "rta = pd.read_csv(dataDir + 'rta.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "#Participation Targets Overall\n",
    "pTargets = pd.read_csv(dataDir + 'participation-targets.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "#School Indicators Table \n",
    "schoolInds = pd.read_csv(dataDir + 'school-indicators.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "schoolIndsCols = list(schoolInds.columns)\n",
    "f = open(tcd + \"schoolIndsCols_15.pkl\",\"wb\")\n",
    "pickle.dump(schoolIndsCols,f)\n",
    "f.close()\n",
    "print (schoolIndsCols)\n",
    "\n",
    "\n",
    "#Specialized Course Enrollment \n",
    "sce = pd.read_csv(dataDir + 'sce.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "sceCols = list(sce.columns)\n",
    "f = open(tcd + \"sceCols_15.pkl\",\"wb\")\n",
    "pickle.dump(sceCols,f)\n",
    "f.close()\n",
    "print (sceCols)\n",
    "\n",
    "#College Enrollment Table\n",
    "collegeEnroll = pd.read_csv(dataDir + 'college-enrollment.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "collegeEnrollCols = list(collegeEnroll.columns)\n",
    "f = open(tcd + \"collegeEnrollCols_15.pkl\",\"wb\")\n",
    "pickle.dump(collegeEnrollCols,f)\n",
    "f.close()\n",
    "print (collegeEnrollCols)\n",
    "\n",
    "#Environment Table\n",
    "environment = pd.read_csv(dataDir + 'environment.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "environmentCols = list(environment.columns)\n",
    "f = open(tcd + \"environmentCols_15.pkl\",\"wb\")\n",
    "pickle.dump(environmentCols,f)\n",
    "f.close()\n",
    "print (environmentCols)\n",
    "\n",
    "#Personnel Table\n",
    "personnel = pd.read_csv(dataDir + 'personnel.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "## Save Columns to Pickle File\n",
    "personnelCols = list(personnel.columns)\n",
    "f = open(tcd + \"personnelCols_15.pkl\",\"wb\")\n",
    "pickle.dump(personnelCols,f)\n",
    "f.close()\n",
    "print (personnelCols)\n",
    "\n",
    "#Educator Experience Table (YOE)\n",
    "yoe = pd.read_csv(dataDir + 'yoe.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "#Educator Effectiveness Table \n",
    "effectiveness = pd.read_csv(dataDir + 'effectiveness.csv', low_memory=False, dtype={'unit_code': object}) \n",
    "\n",
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "ec_pupils = pd.read_csv(dataDir + 'ec_pupils.csv', low_memory=False, dtype={'unit_code': object})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape tables as needed to one record per school "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', '00_Size', '01_Size', '02_Size', '03_Size', '04_Size', '05_Size', '06_Size', '07_Size', '08_Size', 'Biology_Size', 'English II_Size', 'Math I_Size']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#Profile Metric Table Reshape\n",
    "#***********************************************************************\n",
    "\n",
    "#get rid of state and district level records (this information is also in the school level records)\n",
    "profileMetric = profileMetric[  (profileMetric['unit_code'] != 'NC-SEA') \n",
    "                              & (profileMetric['unit_code'].str.contains(\"LEA\") == False)]\n",
    "#Pivot table creating one record per unit_code / school campus\n",
    "profileMetric = pd.pivot_table(profileMetric, values='size',index=['unit_code'],columns=['level'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "profileMetric.columns = [col + '_Size' for col in profileMetric.columns]\n",
    "#Make our index a column for merges later\n",
    "profileMetric.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "profileMetricCols = list(profileMetric.columns)\n",
    "f = open(tcd + \"profileMetricCols_15.pkl\",\"wb\")\n",
    "pickle.dump(profileMetricCols,f)\n",
    "f.close()\n",
    "print (profileMetricCols)\n",
    "#******  Could go back and add size - district and size - state features here!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'ACTCompositeScore_UNCMin_All', 'ACTEnglish_ACTBenchmark_All', 'ACTMath_ACTBenchmark_All', 'ACTReading_ACTBenchmark_All', 'ACTScience_ACTBenchmark_All', 'ACTSubtests_BenchmarksMet_All', 'ACTWorkKeys_SilverPlus_All', 'ACTWriting_ACTBenchmark_All', 'EOCBiology_CACR_All', 'EOCBiology_GLP_All', 'EOCEnglish2_CACR_All', 'EOCEnglish2_GLP_All', 'EOCMathI_CACR_All', 'EOCMathI_GLP_All', 'EOCSubjects_CACR_All', 'EOCSubjects_GLP_All', 'EOG/EOCSubjects_CACR_All', 'EOG/EOCSubjects_GLP_All', 'EOGGr3_CACR_All', 'EOGGr3_GLP_All', 'EOGGr4_CACR_All', 'EOGGr4_GLP_All', 'EOGGr5_CACR_All', 'EOGGr5_GLP_All', 'EOGGr6_CACR_All', 'EOGGr6_GLP_All', 'EOGGr7_CACR_All', 'EOGGr7_GLP_All', 'EOGGr8_CACR_All', 'EOGGr8_GLP_All', 'EOGMathGr3_CACR_All', 'EOGMathGr3_GLP_All', 'EOGMathGr3-8_CACR_All', 'EOGMathGr3-8_GLP_All', 'EOGMathGr4_CACR_All', 'EOGMathGr4_GLP_All', 'EOGMathGr5_CACR_All', 'EOGMathGr5_GLP_All', 'EOGMathGr6_CACR_All', 'EOGMathGr6_GLP_All', 'EOGMathGr7_CACR_All', 'EOGMathGr7_GLP_All', 'EOGMathGr8_CACR_All', 'EOGMathGr8_GLP_All', 'EOGReadingGr3_CACR_All', 'EOGReadingGr3_GLP_All', 'EOGReadingGr3-8_CACR_All', 'EOGReadingGr3-8_GLP_All', 'EOGReadingGr4_CACR_All', 'EOGReadingGr4_GLP_All', 'EOGReadingGr5_CACR_All', 'EOGReadingGr5_GLP_All', 'EOGReadingGr6_CACR_All', 'EOGReadingGr6_GLP_All', 'EOGReadingGr7_CACR_All', 'EOGReadingGr7_GLP_All', 'EOGReadingGr8_CACR_All', 'EOGReadingGr8_GLP_All', 'EOGScienceGr5_CACR_All', 'EOGScienceGr5_GLP_All', 'EOGScienceGr5&8_CACR_All', 'EOGScienceGr5&8_GLP_All', 'EOGScienceGr8_CACR_All', 'EOGScienceGr8_GLP_All', 'EOGSubjects_CACR_All', 'EOGSubjects_GLP_All', 'GraduationRate_4yr_All', 'GraduationRate_5yr_All']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_Female', 'ACTEnglish_ACTBenchmark_Female', 'ACTMath_ACTBenchmark_Female', 'ACTReading_ACTBenchmark_Female', 'ACTScience_ACTBenchmark_Female', 'ACTSubtests_BenchmarksMet_Female', 'ACTWorkKeys_SilverPlus_Female', 'ACTWriting_ACTBenchmark_Female', 'EOCBiology_CACR_Female', 'EOCBiology_GLP_Female', 'EOCEnglish2_CACR_Female', 'EOCEnglish2_GLP_Female', 'EOCMathI_CACR_Female', 'EOCMathI_GLP_Female', 'EOCSubjects_CACR_Female', 'EOCSubjects_GLP_Female', 'EOG/EOCSubjects_CACR_Female', 'EOG/EOCSubjects_GLP_Female', 'EOGGr3_CACR_Female', 'EOGGr3_GLP_Female', 'EOGGr4_CACR_Female', 'EOGGr4_GLP_Female', 'EOGGr5_CACR_Female', 'EOGGr5_GLP_Female', 'EOGGr6_CACR_Female', 'EOGGr6_GLP_Female', 'EOGGr7_CACR_Female', 'EOGGr7_GLP_Female', 'EOGGr8_CACR_Female', 'EOGGr8_GLP_Female', 'EOGMathGr3_CACR_Female', 'EOGMathGr3_GLP_Female', 'EOGMathGr3-8_CACR_Female', 'EOGMathGr3-8_GLP_Female', 'EOGMathGr4_CACR_Female', 'EOGMathGr4_GLP_Female', 'EOGMathGr5_CACR_Female', 'EOGMathGr5_GLP_Female', 'EOGMathGr6_CACR_Female', 'EOGMathGr6_GLP_Female', 'EOGMathGr7_CACR_Female', 'EOGMathGr7_GLP_Female', 'EOGMathGr8_CACR_Female', 'EOGMathGr8_GLP_Female', 'EOGReadingGr3_CACR_Female', 'EOGReadingGr3_GLP_Female', 'EOGReadingGr3-8_CACR_Female', 'EOGReadingGr3-8_GLP_Female', 'EOGReadingGr4_CACR_Female', 'EOGReadingGr4_GLP_Female', 'EOGReadingGr5_CACR_Female', 'EOGReadingGr5_GLP_Female', 'EOGReadingGr6_CACR_Female', 'EOGReadingGr6_GLP_Female', 'EOGReadingGr7_CACR_Female', 'EOGReadingGr7_GLP_Female', 'EOGReadingGr8_CACR_Female', 'EOGReadingGr8_GLP_Female', 'EOGScienceGr5_CACR_Female', 'EOGScienceGr5_GLP_Female', 'EOGScienceGr5&8_CACR_Female', 'EOGScienceGr5&8_GLP_Female', 'EOGScienceGr8_CACR_Female', 'EOGScienceGr8_GLP_Female', 'EOGSubjects_CACR_Female', 'EOGSubjects_GLP_Female', 'GraduationRate_4yr_Female', 'GraduationRate_5yr_Female']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_Male', 'ACTEnglish_ACTBenchmark_Male', 'ACTMath_ACTBenchmark_Male', 'ACTReading_ACTBenchmark_Male', 'ACTScience_ACTBenchmark_Male', 'ACTSubtests_BenchmarksMet_Male', 'ACTWorkKeys_SilverPlus_Male', 'ACTWriting_ACTBenchmark_Male', 'EOCBiology_CACR_Male', 'EOCBiology_GLP_Male', 'EOCEnglish2_CACR_Male', 'EOCEnglish2_GLP_Male', 'EOCMathI_CACR_Male', 'EOCMathI_GLP_Male', 'EOCSubjects_CACR_Male', 'EOCSubjects_GLP_Male', 'EOG/EOCSubjects_CACR_Male', 'EOG/EOCSubjects_GLP_Male', 'EOGGr3_CACR_Male', 'EOGGr3_GLP_Male', 'EOGGr4_CACR_Male', 'EOGGr4_GLP_Male', 'EOGGr5_CACR_Male', 'EOGGr5_GLP_Male', 'EOGGr6_CACR_Male', 'EOGGr6_GLP_Male', 'EOGGr7_CACR_Male', 'EOGGr7_GLP_Male', 'EOGGr8_CACR_Male', 'EOGGr8_GLP_Male', 'EOGMathGr3_CACR_Male', 'EOGMathGr3_GLP_Male', 'EOGMathGr3-8_CACR_Male', 'EOGMathGr3-8_GLP_Male', 'EOGMathGr4_CACR_Male', 'EOGMathGr4_GLP_Male', 'EOGMathGr5_CACR_Male', 'EOGMathGr5_GLP_Male', 'EOGMathGr6_CACR_Male', 'EOGMathGr6_GLP_Male', 'EOGMathGr7_CACR_Male', 'EOGMathGr7_GLP_Male', 'EOGMathGr8_CACR_Male', 'EOGMathGr8_GLP_Male', 'EOGReadingGr3_CACR_Male', 'EOGReadingGr3_GLP_Male', 'EOGReadingGr3-8_CACR_Male', 'EOGReadingGr3-8_GLP_Male', 'EOGReadingGr4_CACR_Male', 'EOGReadingGr4_GLP_Male', 'EOGReadingGr5_CACR_Male', 'EOGReadingGr5_GLP_Male', 'EOGReadingGr6_CACR_Male', 'EOGReadingGr6_GLP_Male', 'EOGReadingGr7_CACR_Male', 'EOGReadingGr7_GLP_Male', 'EOGReadingGr8_CACR_Male', 'EOGReadingGr8_GLP_Male', 'EOGScienceGr5_CACR_Male', 'EOGScienceGr5_GLP_Male', 'EOGScienceGr5&8_CACR_Male', 'EOGScienceGr5&8_GLP_Male', 'EOGScienceGr8_CACR_Male', 'EOGScienceGr8_GLP_Male', 'EOGSubjects_CACR_Male', 'EOGSubjects_GLP_Male', 'GraduationRate_4yr_Male', 'GraduationRate_5yr_Male']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_AmericanIndian', 'ACTEnglish_ACTBenchmark_AmericanIndian', 'ACTMath_ACTBenchmark_AmericanIndian', 'ACTReading_ACTBenchmark_AmericanIndian', 'ACTScience_ACTBenchmark_AmericanIndian', 'ACTSubtests_BenchmarksMet_AmericanIndian', 'ACTWorkKeys_SilverPlus_AmericanIndian', 'ACTWriting_ACTBenchmark_AmericanIndian', 'EOCBiology_CACR_AmericanIndian', 'EOCBiology_GLP_AmericanIndian', 'EOCEnglish2_CACR_AmericanIndian', 'EOCEnglish2_GLP_AmericanIndian', 'EOCMathI_CACR_AmericanIndian', 'EOCMathI_GLP_AmericanIndian', 'EOCSubjects_CACR_AmericanIndian', 'EOCSubjects_GLP_AmericanIndian', 'EOG/EOCSubjects_CACR_AmericanIndian', 'EOG/EOCSubjects_GLP_AmericanIndian', 'EOGGr3_CACR_AmericanIndian', 'EOGGr3_GLP_AmericanIndian', 'EOGGr4_CACR_AmericanIndian', 'EOGGr4_GLP_AmericanIndian', 'EOGGr5_CACR_AmericanIndian', 'EOGGr5_GLP_AmericanIndian', 'EOGGr6_CACR_AmericanIndian', 'EOGGr6_GLP_AmericanIndian', 'EOGGr7_CACR_AmericanIndian', 'EOGGr7_GLP_AmericanIndian', 'EOGGr8_CACR_AmericanIndian', 'EOGGr8_GLP_AmericanIndian', 'EOGMathGr3_CACR_AmericanIndian', 'EOGMathGr3_GLP_AmericanIndian', 'EOGMathGr3-8_CACR_AmericanIndian', 'EOGMathGr3-8_GLP_AmericanIndian', 'EOGMathGr4_CACR_AmericanIndian', 'EOGMathGr4_GLP_AmericanIndian', 'EOGMathGr5_CACR_AmericanIndian', 'EOGMathGr5_GLP_AmericanIndian', 'EOGMathGr6_CACR_AmericanIndian', 'EOGMathGr6_GLP_AmericanIndian', 'EOGMathGr7_CACR_AmericanIndian', 'EOGMathGr7_GLP_AmericanIndian', 'EOGMathGr8_CACR_AmericanIndian', 'EOGMathGr8_GLP_AmericanIndian', 'EOGReadingGr3_CACR_AmericanIndian', 'EOGReadingGr3_GLP_AmericanIndian', 'EOGReadingGr3-8_CACR_AmericanIndian', 'EOGReadingGr3-8_GLP_AmericanIndian', 'EOGReadingGr4_CACR_AmericanIndian', 'EOGReadingGr4_GLP_AmericanIndian', 'EOGReadingGr5_CACR_AmericanIndian', 'EOGReadingGr5_GLP_AmericanIndian', 'EOGReadingGr6_CACR_AmericanIndian', 'EOGReadingGr6_GLP_AmericanIndian', 'EOGReadingGr7_CACR_AmericanIndian', 'EOGReadingGr7_GLP_AmericanIndian', 'EOGReadingGr8_CACR_AmericanIndian', 'EOGReadingGr8_GLP_AmericanIndian', 'EOGScienceGr5_CACR_AmericanIndian', 'EOGScienceGr5_GLP_AmericanIndian', 'EOGScienceGr5&8_CACR_AmericanIndian', 'EOGScienceGr5&8_GLP_AmericanIndian', 'EOGScienceGr8_CACR_AmericanIndian', 'EOGScienceGr8_GLP_AmericanIndian', 'EOGSubjects_CACR_AmericanIndian', 'EOGSubjects_GLP_AmericanIndian', 'GraduationRate_4yr_AmericanIndian', 'GraduationRate_5yr_AmericanIndian']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_Asian', 'ACTEnglish_ACTBenchmark_Asian', 'ACTMath_ACTBenchmark_Asian', 'ACTReading_ACTBenchmark_Asian', 'ACTScience_ACTBenchmark_Asian', 'ACTSubtests_BenchmarksMet_Asian', 'ACTWorkKeys_SilverPlus_Asian', 'ACTWriting_ACTBenchmark_Asian', 'EOCBiology_CACR_Asian', 'EOCBiology_GLP_Asian', 'EOCEnglish2_CACR_Asian', 'EOCEnglish2_GLP_Asian', 'EOCMathI_CACR_Asian', 'EOCMathI_GLP_Asian', 'EOCSubjects_CACR_Asian', 'EOCSubjects_GLP_Asian', 'EOG/EOCSubjects_CACR_Asian', 'EOG/EOCSubjects_GLP_Asian', 'EOGGr3_CACR_Asian', 'EOGGr3_GLP_Asian', 'EOGGr4_CACR_Asian', 'EOGGr4_GLP_Asian', 'EOGGr5_CACR_Asian', 'EOGGr5_GLP_Asian', 'EOGGr6_CACR_Asian', 'EOGGr6_GLP_Asian', 'EOGGr7_CACR_Asian', 'EOGGr7_GLP_Asian', 'EOGGr8_CACR_Asian', 'EOGGr8_GLP_Asian', 'EOGMathGr3_CACR_Asian', 'EOGMathGr3_GLP_Asian', 'EOGMathGr3-8_CACR_Asian', 'EOGMathGr3-8_GLP_Asian', 'EOGMathGr4_CACR_Asian', 'EOGMathGr4_GLP_Asian', 'EOGMathGr5_CACR_Asian', 'EOGMathGr5_GLP_Asian', 'EOGMathGr6_CACR_Asian', 'EOGMathGr6_GLP_Asian', 'EOGMathGr7_CACR_Asian', 'EOGMathGr7_GLP_Asian', 'EOGMathGr8_CACR_Asian', 'EOGMathGr8_GLP_Asian', 'EOGReadingGr3_CACR_Asian', 'EOGReadingGr3_GLP_Asian', 'EOGReadingGr3-8_CACR_Asian', 'EOGReadingGr3-8_GLP_Asian', 'EOGReadingGr4_CACR_Asian', 'EOGReadingGr4_GLP_Asian', 'EOGReadingGr5_CACR_Asian', 'EOGReadingGr5_GLP_Asian', 'EOGReadingGr6_CACR_Asian', 'EOGReadingGr6_GLP_Asian', 'EOGReadingGr7_CACR_Asian', 'EOGReadingGr7_GLP_Asian', 'EOGReadingGr8_CACR_Asian', 'EOGReadingGr8_GLP_Asian', 'EOGScienceGr5_CACR_Asian', 'EOGScienceGr5_GLP_Asian', 'EOGScienceGr5&8_CACR_Asian', 'EOGScienceGr5&8_GLP_Asian', 'EOGScienceGr8_CACR_Asian', 'EOGScienceGr8_GLP_Asian', 'EOGSubjects_CACR_Asian', 'EOGSubjects_GLP_Asian', 'GraduationRate_4yr_Asian', 'GraduationRate_5yr_Asian']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'ACTCompositeScore_UNCMin_Black', 'ACTEnglish_ACTBenchmark_Black', 'ACTMath_ACTBenchmark_Black', 'ACTReading_ACTBenchmark_Black', 'ACTScience_ACTBenchmark_Black', 'ACTSubtests_BenchmarksMet_Black', 'ACTWorkKeys_SilverPlus_Black', 'ACTWriting_ACTBenchmark_Black', 'EOCBiology_CACR_Black', 'EOCBiology_GLP_Black', 'EOCEnglish2_CACR_Black', 'EOCEnglish2_GLP_Black', 'EOCMathI_CACR_Black', 'EOCMathI_GLP_Black', 'EOCSubjects_CACR_Black', 'EOCSubjects_GLP_Black', 'EOG/EOCSubjects_CACR_Black', 'EOG/EOCSubjects_GLP_Black', 'EOGGr3_CACR_Black', 'EOGGr3_GLP_Black', 'EOGGr4_CACR_Black', 'EOGGr4_GLP_Black', 'EOGGr5_CACR_Black', 'EOGGr5_GLP_Black', 'EOGGr6_CACR_Black', 'EOGGr6_GLP_Black', 'EOGGr7_CACR_Black', 'EOGGr7_GLP_Black', 'EOGGr8_CACR_Black', 'EOGGr8_GLP_Black', 'EOGMathGr3_CACR_Black', 'EOGMathGr3_GLP_Black', 'EOGMathGr3-8_CACR_Black', 'EOGMathGr3-8_GLP_Black', 'EOGMathGr4_CACR_Black', 'EOGMathGr4_GLP_Black', 'EOGMathGr5_CACR_Black', 'EOGMathGr5_GLP_Black', 'EOGMathGr6_CACR_Black', 'EOGMathGr6_GLP_Black', 'EOGMathGr7_CACR_Black', 'EOGMathGr7_GLP_Black', 'EOGMathGr8_CACR_Black', 'EOGMathGr8_GLP_Black', 'EOGReadingGr3_CACR_Black', 'EOGReadingGr3_GLP_Black', 'EOGReadingGr3-8_CACR_Black', 'EOGReadingGr3-8_GLP_Black', 'EOGReadingGr4_CACR_Black', 'EOGReadingGr4_GLP_Black', 'EOGReadingGr5_CACR_Black', 'EOGReadingGr5_GLP_Black', 'EOGReadingGr6_CACR_Black', 'EOGReadingGr6_GLP_Black', 'EOGReadingGr7_CACR_Black', 'EOGReadingGr7_GLP_Black', 'EOGReadingGr8_CACR_Black', 'EOGReadingGr8_GLP_Black', 'EOGScienceGr5_CACR_Black', 'EOGScienceGr5_GLP_Black', 'EOGScienceGr5&8_CACR_Black', 'EOGScienceGr5&8_GLP_Black', 'EOGScienceGr8_CACR_Black', 'EOGScienceGr8_GLP_Black', 'EOGSubjects_CACR_Black', 'EOGSubjects_GLP_Black', 'GraduationRate_4yr_Black', 'GraduationRate_5yr_Black']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_Hispanic', 'ACTEnglish_ACTBenchmark_Hispanic', 'ACTMath_ACTBenchmark_Hispanic', 'ACTReading_ACTBenchmark_Hispanic', 'ACTScience_ACTBenchmark_Hispanic', 'ACTSubtests_BenchmarksMet_Hispanic', 'ACTWorkKeys_SilverPlus_Hispanic', 'ACTWriting_ACTBenchmark_Hispanic', 'EOCBiology_CACR_Hispanic', 'EOCBiology_GLP_Hispanic', 'EOCEnglish2_CACR_Hispanic', 'EOCEnglish2_GLP_Hispanic', 'EOCMathI_CACR_Hispanic', 'EOCMathI_GLP_Hispanic', 'EOCSubjects_CACR_Hispanic', 'EOCSubjects_GLP_Hispanic', 'EOG/EOCSubjects_CACR_Hispanic', 'EOG/EOCSubjects_GLP_Hispanic', 'EOGGr3_CACR_Hispanic', 'EOGGr3_GLP_Hispanic', 'EOGGr4_CACR_Hispanic', 'EOGGr4_GLP_Hispanic', 'EOGGr5_CACR_Hispanic', 'EOGGr5_GLP_Hispanic', 'EOGGr6_CACR_Hispanic', 'EOGGr6_GLP_Hispanic', 'EOGGr7_CACR_Hispanic', 'EOGGr7_GLP_Hispanic', 'EOGGr8_CACR_Hispanic', 'EOGGr8_GLP_Hispanic', 'EOGMathGr3_CACR_Hispanic', 'EOGMathGr3_GLP_Hispanic', 'EOGMathGr3-8_CACR_Hispanic', 'EOGMathGr3-8_GLP_Hispanic', 'EOGMathGr4_CACR_Hispanic', 'EOGMathGr4_GLP_Hispanic', 'EOGMathGr5_CACR_Hispanic', 'EOGMathGr5_GLP_Hispanic', 'EOGMathGr6_CACR_Hispanic', 'EOGMathGr6_GLP_Hispanic', 'EOGMathGr7_CACR_Hispanic', 'EOGMathGr7_GLP_Hispanic', 'EOGMathGr8_CACR_Hispanic', 'EOGMathGr8_GLP_Hispanic', 'EOGReadingGr3_CACR_Hispanic', 'EOGReadingGr3_GLP_Hispanic', 'EOGReadingGr3-8_CACR_Hispanic', 'EOGReadingGr3-8_GLP_Hispanic', 'EOGReadingGr4_CACR_Hispanic', 'EOGReadingGr4_GLP_Hispanic', 'EOGReadingGr5_CACR_Hispanic', 'EOGReadingGr5_GLP_Hispanic', 'EOGReadingGr6_CACR_Hispanic', 'EOGReadingGr6_GLP_Hispanic', 'EOGReadingGr7_CACR_Hispanic', 'EOGReadingGr7_GLP_Hispanic', 'EOGReadingGr8_CACR_Hispanic', 'EOGReadingGr8_GLP_Hispanic', 'EOGScienceGr5_CACR_Hispanic', 'EOGScienceGr5_GLP_Hispanic', 'EOGScienceGr5&8_CACR_Hispanic', 'EOGScienceGr5&8_GLP_Hispanic', 'EOGScienceGr8_CACR_Hispanic', 'EOGScienceGr8_GLP_Hispanic', 'EOGSubjects_CACR_Hispanic', 'EOGSubjects_GLP_Hispanic', 'GraduationRate_4yr_Hispanic', 'GraduationRate_5yr_Hispanic']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_TwoorMoreRaces', 'ACTEnglish_ACTBenchmark_TwoorMoreRaces', 'ACTMath_ACTBenchmark_TwoorMoreRaces', 'ACTReading_ACTBenchmark_TwoorMoreRaces', 'ACTScience_ACTBenchmark_TwoorMoreRaces', 'ACTSubtests_BenchmarksMet_TwoorMoreRaces', 'ACTWorkKeys_SilverPlus_TwoorMoreRaces', 'ACTWriting_ACTBenchmark_TwoorMoreRaces', 'EOCBiology_CACR_TwoorMoreRaces', 'EOCBiology_GLP_TwoorMoreRaces', 'EOCEnglish2_CACR_TwoorMoreRaces', 'EOCEnglish2_GLP_TwoorMoreRaces', 'EOCMathI_CACR_TwoorMoreRaces', 'EOCMathI_GLP_TwoorMoreRaces', 'EOCSubjects_CACR_TwoorMoreRaces', 'EOCSubjects_GLP_TwoorMoreRaces', 'EOG/EOCSubjects_CACR_TwoorMoreRaces', 'EOG/EOCSubjects_GLP_TwoorMoreRaces', 'EOGGr3_CACR_TwoorMoreRaces', 'EOGGr3_GLP_TwoorMoreRaces', 'EOGGr4_CACR_TwoorMoreRaces', 'EOGGr4_GLP_TwoorMoreRaces', 'EOGGr5_CACR_TwoorMoreRaces', 'EOGGr5_GLP_TwoorMoreRaces', 'EOGGr6_CACR_TwoorMoreRaces', 'EOGGr6_GLP_TwoorMoreRaces', 'EOGGr7_CACR_TwoorMoreRaces', 'EOGGr7_GLP_TwoorMoreRaces', 'EOGGr8_CACR_TwoorMoreRaces', 'EOGGr8_GLP_TwoorMoreRaces', 'EOGMathGr3_CACR_TwoorMoreRaces', 'EOGMathGr3_GLP_TwoorMoreRaces', 'EOGMathGr3-8_CACR_TwoorMoreRaces', 'EOGMathGr3-8_GLP_TwoorMoreRaces', 'EOGMathGr4_CACR_TwoorMoreRaces', 'EOGMathGr4_GLP_TwoorMoreRaces', 'EOGMathGr5_CACR_TwoorMoreRaces', 'EOGMathGr5_GLP_TwoorMoreRaces', 'EOGMathGr6_CACR_TwoorMoreRaces', 'EOGMathGr6_GLP_TwoorMoreRaces', 'EOGMathGr7_CACR_TwoorMoreRaces', 'EOGMathGr7_GLP_TwoorMoreRaces', 'EOGMathGr8_CACR_TwoorMoreRaces', 'EOGMathGr8_GLP_TwoorMoreRaces', 'EOGReadingGr3_CACR_TwoorMoreRaces', 'EOGReadingGr3_GLP_TwoorMoreRaces', 'EOGReadingGr3-8_CACR_TwoorMoreRaces', 'EOGReadingGr3-8_GLP_TwoorMoreRaces', 'EOGReadingGr4_CACR_TwoorMoreRaces', 'EOGReadingGr4_GLP_TwoorMoreRaces', 'EOGReadingGr5_CACR_TwoorMoreRaces', 'EOGReadingGr5_GLP_TwoorMoreRaces', 'EOGReadingGr6_CACR_TwoorMoreRaces', 'EOGReadingGr6_GLP_TwoorMoreRaces', 'EOGReadingGr7_CACR_TwoorMoreRaces', 'EOGReadingGr7_GLP_TwoorMoreRaces', 'EOGReadingGr8_CACR_TwoorMoreRaces', 'EOGReadingGr8_GLP_TwoorMoreRaces', 'EOGScienceGr5_CACR_TwoorMoreRaces', 'EOGScienceGr5_GLP_TwoorMoreRaces', 'EOGScienceGr5&8_CACR_TwoorMoreRaces', 'EOGScienceGr5&8_GLP_TwoorMoreRaces', 'EOGScienceGr8_CACR_TwoorMoreRaces', 'EOGScienceGr8_GLP_TwoorMoreRaces', 'EOGSubjects_CACR_TwoorMoreRaces', 'EOGSubjects_GLP_TwoorMoreRaces', 'GraduationRate_4yr_TwoorMoreRaces', 'GraduationRate_5yr_TwoorMoreRaces']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_White', 'ACTEnglish_ACTBenchmark_White', 'ACTMath_ACTBenchmark_White', 'ACTReading_ACTBenchmark_White', 'ACTScience_ACTBenchmark_White', 'ACTSubtests_BenchmarksMet_White', 'ACTWorkKeys_SilverPlus_White', 'ACTWriting_ACTBenchmark_White', 'EOCBiology_CACR_White', 'EOCBiology_GLP_White', 'EOCEnglish2_CACR_White', 'EOCEnglish2_GLP_White', 'EOCMathI_CACR_White', 'EOCMathI_GLP_White', 'EOCSubjects_CACR_White', 'EOCSubjects_GLP_White', 'EOG/EOCSubjects_CACR_White', 'EOG/EOCSubjects_GLP_White', 'EOGGr3_CACR_White', 'EOGGr3_GLP_White', 'EOGGr4_CACR_White', 'EOGGr4_GLP_White', 'EOGGr5_CACR_White', 'EOGGr5_GLP_White', 'EOGGr6_CACR_White', 'EOGGr6_GLP_White', 'EOGGr7_CACR_White', 'EOGGr7_GLP_White', 'EOGGr8_CACR_White', 'EOGGr8_GLP_White', 'EOGMathGr3_CACR_White', 'EOGMathGr3_GLP_White', 'EOGMathGr3-8_CACR_White', 'EOGMathGr3-8_GLP_White', 'EOGMathGr4_CACR_White', 'EOGMathGr4_GLP_White', 'EOGMathGr5_CACR_White', 'EOGMathGr5_GLP_White', 'EOGMathGr6_CACR_White', 'EOGMathGr6_GLP_White', 'EOGMathGr7_CACR_White', 'EOGMathGr7_GLP_White', 'EOGMathGr8_CACR_White', 'EOGMathGr8_GLP_White', 'EOGReadingGr3_CACR_White', 'EOGReadingGr3_GLP_White', 'EOGReadingGr3-8_CACR_White', 'EOGReadingGr3-8_GLP_White', 'EOGReadingGr4_CACR_White', 'EOGReadingGr4_GLP_White', 'EOGReadingGr5_CACR_White', 'EOGReadingGr5_GLP_White', 'EOGReadingGr6_CACR_White', 'EOGReadingGr6_GLP_White', 'EOGReadingGr7_CACR_White', 'EOGReadingGr7_GLP_White', 'EOGReadingGr8_CACR_White', 'EOGReadingGr8_GLP_White', 'EOGScienceGr5_CACR_White', 'EOGScienceGr5_GLP_White', 'EOGScienceGr5&8_CACR_White', 'EOGScienceGr5&8_GLP_White', 'EOGScienceGr8_CACR_White', 'EOGScienceGr8_GLP_White', 'EOGSubjects_CACR_White', 'EOGSubjects_GLP_White', 'GraduationRate_4yr_White', 'GraduationRate_5yr_White']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_EDS', 'ACTEnglish_ACTBenchmark_EDS', 'ACTMath_ACTBenchmark_EDS', 'ACTReading_ACTBenchmark_EDS', 'ACTScience_ACTBenchmark_EDS', 'ACTSubtests_BenchmarksMet_EDS', 'ACTWorkKeys_SilverPlus_EDS', 'ACTWriting_ACTBenchmark_EDS', 'EOCBiology_CACR_EDS', 'EOCBiology_GLP_EDS', 'EOCEnglish2_CACR_EDS', 'EOCEnglish2_GLP_EDS', 'EOCMathI_CACR_EDS', 'EOCMathI_GLP_EDS', 'EOCSubjects_CACR_EDS', 'EOCSubjects_GLP_EDS', 'EOG/EOCSubjects_CACR_EDS', 'EOG/EOCSubjects_GLP_EDS', 'EOGGr3_CACR_EDS', 'EOGGr3_GLP_EDS', 'EOGGr4_CACR_EDS', 'EOGGr4_GLP_EDS', 'EOGGr5_CACR_EDS', 'EOGGr5_GLP_EDS', 'EOGGr6_CACR_EDS', 'EOGGr6_GLP_EDS', 'EOGGr7_CACR_EDS', 'EOGGr7_GLP_EDS', 'EOGGr8_CACR_EDS', 'EOGGr8_GLP_EDS', 'EOGMathGr3_CACR_EDS', 'EOGMathGr3_GLP_EDS', 'EOGMathGr3-8_CACR_EDS', 'EOGMathGr3-8_GLP_EDS', 'EOGMathGr4_CACR_EDS', 'EOGMathGr4_GLP_EDS', 'EOGMathGr5_CACR_EDS', 'EOGMathGr5_GLP_EDS', 'EOGMathGr6_CACR_EDS', 'EOGMathGr6_GLP_EDS', 'EOGMathGr7_CACR_EDS', 'EOGMathGr7_GLP_EDS', 'EOGMathGr8_CACR_EDS', 'EOGMathGr8_GLP_EDS', 'EOGReadingGr3_CACR_EDS', 'EOGReadingGr3_GLP_EDS', 'EOGReadingGr3-8_CACR_EDS', 'EOGReadingGr3-8_GLP_EDS', 'EOGReadingGr4_CACR_EDS', 'EOGReadingGr4_GLP_EDS', 'EOGReadingGr5_CACR_EDS', 'EOGReadingGr5_GLP_EDS', 'EOGReadingGr6_CACR_EDS', 'EOGReadingGr6_GLP_EDS', 'EOGReadingGr7_CACR_EDS', 'EOGReadingGr7_GLP_EDS', 'EOGReadingGr8_CACR_EDS', 'EOGReadingGr8_GLP_EDS', 'EOGScienceGr5_CACR_EDS', 'EOGScienceGr5_GLP_EDS', 'EOGScienceGr5&8_CACR_EDS', 'EOGScienceGr5&8_GLP_EDS', 'EOGScienceGr8_CACR_EDS', 'EOGScienceGr8_GLP_EDS', 'EOGSubjects_CACR_EDS', 'EOGSubjects_GLP_EDS', 'GraduationRate_4yr_EDS', 'GraduationRate_5yr_EDS']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'ACTCompositeScore_UNCMin_LEP', 'ACTEnglish_ACTBenchmark_LEP', 'ACTMath_ACTBenchmark_LEP', 'ACTReading_ACTBenchmark_LEP', 'ACTScience_ACTBenchmark_LEP', 'ACTSubtests_BenchmarksMet_LEP', 'ACTWorkKeys_SilverPlus_LEP', 'ACTWriting_ACTBenchmark_LEP', 'EOCBiology_CACR_LEP', 'EOCBiology_GLP_LEP', 'EOCEnglish2_CACR_LEP', 'EOCEnglish2_GLP_LEP', 'EOCMathI_CACR_LEP', 'EOCMathI_GLP_LEP', 'EOCSubjects_CACR_LEP', 'EOCSubjects_GLP_LEP', 'EOG/EOCSubjects_CACR_LEP', 'EOG/EOCSubjects_GLP_LEP', 'EOGGr3_CACR_LEP', 'EOGGr3_GLP_LEP', 'EOGGr4_CACR_LEP', 'EOGGr4_GLP_LEP', 'EOGGr5_CACR_LEP', 'EOGGr5_GLP_LEP', 'EOGGr6_CACR_LEP', 'EOGGr6_GLP_LEP', 'EOGGr7_CACR_LEP', 'EOGGr7_GLP_LEP', 'EOGGr8_CACR_LEP', 'EOGGr8_GLP_LEP', 'EOGMathGr3_CACR_LEP', 'EOGMathGr3_GLP_LEP', 'EOGMathGr3-8_CACR_LEP', 'EOGMathGr3-8_GLP_LEP', 'EOGMathGr4_CACR_LEP', 'EOGMathGr4_GLP_LEP', 'EOGMathGr5_CACR_LEP', 'EOGMathGr5_GLP_LEP', 'EOGMathGr6_CACR_LEP', 'EOGMathGr6_GLP_LEP', 'EOGMathGr7_CACR_LEP', 'EOGMathGr7_GLP_LEP', 'EOGMathGr8_CACR_LEP', 'EOGMathGr8_GLP_LEP', 'EOGReadingGr3_CACR_LEP', 'EOGReadingGr3_GLP_LEP', 'EOGReadingGr3-8_CACR_LEP', 'EOGReadingGr3-8_GLP_LEP', 'EOGReadingGr4_CACR_LEP', 'EOGReadingGr4_GLP_LEP', 'EOGReadingGr5_CACR_LEP', 'EOGReadingGr5_GLP_LEP', 'EOGReadingGr6_CACR_LEP', 'EOGReadingGr6_GLP_LEP', 'EOGReadingGr7_CACR_LEP', 'EOGReadingGr7_GLP_LEP', 'EOGReadingGr8_CACR_LEP', 'EOGReadingGr8_GLP_LEP', 'EOGScienceGr5_CACR_LEP', 'EOGScienceGr5_GLP_LEP', 'EOGScienceGr5&8_CACR_LEP', 'EOGScienceGr5&8_GLP_LEP', 'EOGScienceGr8_CACR_LEP', 'EOGScienceGr8_GLP_LEP', 'EOGSubjects_CACR_LEP', 'EOGSubjects_GLP_LEP', 'GraduationRate_4yr_LEP', 'GraduationRate_5yr_LEP']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_SWD', 'ACTEnglish_ACTBenchmark_SWD', 'ACTMath_ACTBenchmark_SWD', 'ACTReading_ACTBenchmark_SWD', 'ACTScience_ACTBenchmark_SWD', 'ACTSubtests_BenchmarksMet_SWD', 'ACTWorkKeys_SilverPlus_SWD', 'ACTWriting_ACTBenchmark_SWD', 'EOCBiology_CACR_SWD', 'EOCBiology_GLP_SWD', 'EOCEnglish2_CACR_SWD', 'EOCEnglish2_GLP_SWD', 'EOCMathI_CACR_SWD', 'EOCMathI_GLP_SWD', 'EOCSubjects_CACR_SWD', 'EOCSubjects_GLP_SWD', 'EOG/EOCSubjects_CACR_SWD', 'EOG/EOCSubjects_GLP_SWD', 'EOGGr3_CACR_SWD', 'EOGGr3_GLP_SWD', 'EOGGr4_CACR_SWD', 'EOGGr4_GLP_SWD', 'EOGGr5_CACR_SWD', 'EOGGr5_GLP_SWD', 'EOGGr6_CACR_SWD', 'EOGGr6_GLP_SWD', 'EOGGr7_CACR_SWD', 'EOGGr7_GLP_SWD', 'EOGGr8_CACR_SWD', 'EOGGr8_GLP_SWD', 'EOGMathGr3_CACR_SWD', 'EOGMathGr3_GLP_SWD', 'EOGMathGr3-8_CACR_SWD', 'EOGMathGr3-8_GLP_SWD', 'EOGMathGr4_CACR_SWD', 'EOGMathGr4_GLP_SWD', 'EOGMathGr5_CACR_SWD', 'EOGMathGr5_GLP_SWD', 'EOGMathGr6_CACR_SWD', 'EOGMathGr6_GLP_SWD', 'EOGMathGr7_CACR_SWD', 'EOGMathGr7_GLP_SWD', 'EOGMathGr8_CACR_SWD', 'EOGMathGr8_GLP_SWD', 'EOGReadingGr3_CACR_SWD', 'EOGReadingGr3_GLP_SWD', 'EOGReadingGr3-8_CACR_SWD', 'EOGReadingGr3-8_GLP_SWD', 'EOGReadingGr4_CACR_SWD', 'EOGReadingGr4_GLP_SWD', 'EOGReadingGr5_CACR_SWD', 'EOGReadingGr5_GLP_SWD', 'EOGReadingGr6_CACR_SWD', 'EOGReadingGr6_GLP_SWD', 'EOGReadingGr7_CACR_SWD', 'EOGReadingGr7_GLP_SWD', 'EOGReadingGr8_CACR_SWD', 'EOGReadingGr8_GLP_SWD', 'EOGScienceGr5_CACR_SWD', 'EOGScienceGr5_GLP_SWD', 'EOGScienceGr5&8_CACR_SWD', 'EOGScienceGr5&8_GLP_SWD', 'EOGScienceGr8_CACR_SWD', 'EOGScienceGr8_GLP_SWD', 'EOGSubjects_CACR_SWD', 'EOGSubjects_GLP_SWD', 'GraduationRate_4yr_SWD', 'GraduationRate_5yr_SWD']\n",
      "['unit_code', 'ACTCompositeScore_UNCMin_AIG', 'ACTEnglish_ACTBenchmark_AIG', 'ACTMath_ACTBenchmark_AIG', 'ACTReading_ACTBenchmark_AIG', 'ACTScience_ACTBenchmark_AIG', 'ACTSubtests_BenchmarksMet_AIG', 'ACTWorkKeys_SilverPlus_AIG', 'ACTWriting_ACTBenchmark_AIG', 'EOCBiology_CACR_AIG', 'EOCBiology_GLP_AIG', 'EOCEnglish2_CACR_AIG', 'EOCEnglish2_GLP_AIG', 'EOCMathI_CACR_AIG', 'EOCMathI_GLP_AIG', 'EOCSubjects_CACR_AIG', 'EOCSubjects_GLP_AIG', 'EOG/EOCSubjects_CACR_AIG', 'EOG/EOCSubjects_GLP_AIG', 'EOGGr3_CACR_AIG', 'EOGGr3_GLP_AIG', 'EOGGr4_CACR_AIG', 'EOGGr4_GLP_AIG', 'EOGGr5_CACR_AIG', 'EOGGr5_GLP_AIG', 'EOGGr6_CACR_AIG', 'EOGGr6_GLP_AIG', 'EOGGr7_CACR_AIG', 'EOGGr7_GLP_AIG', 'EOGGr8_CACR_AIG', 'EOGGr8_GLP_AIG', 'EOGMathGr3_CACR_AIG', 'EOGMathGr3_GLP_AIG', 'EOGMathGr3-8_CACR_AIG', 'EOGMathGr3-8_GLP_AIG', 'EOGMathGr4_CACR_AIG', 'EOGMathGr4_GLP_AIG', 'EOGMathGr5_CACR_AIG', 'EOGMathGr5_GLP_AIG', 'EOGMathGr6_CACR_AIG', 'EOGMathGr6_GLP_AIG', 'EOGMathGr7_CACR_AIG', 'EOGMathGr7_GLP_AIG', 'EOGMathGr8_CACR_AIG', 'EOGMathGr8_GLP_AIG', 'EOGReadingGr3_CACR_AIG', 'EOGReadingGr3_GLP_AIG', 'EOGReadingGr3-8_CACR_AIG', 'EOGReadingGr3-8_GLP_AIG', 'EOGReadingGr4_CACR_AIG', 'EOGReadingGr4_GLP_AIG', 'EOGReadingGr5_CACR_AIG', 'EOGReadingGr5_GLP_AIG', 'EOGReadingGr6_CACR_AIG', 'EOGReadingGr6_GLP_AIG', 'EOGReadingGr7_CACR_AIG', 'EOGReadingGr7_GLP_AIG', 'EOGReadingGr8_CACR_AIG', 'EOGReadingGr8_GLP_AIG', 'EOGScienceGr5_CACR_AIG', 'EOGScienceGr5_GLP_AIG', 'EOGScienceGr5&8_CACR_AIG', 'EOGScienceGr5&8_GLP_AIG', 'EOGScienceGr8_CACR_AIG', 'EOGScienceGr8_GLP_AIG', 'EOGSubjects_CACR_AIG', 'EOGSubjects_GLP_AIG', 'GraduationRate_4yr_AIG', 'GraduationRate_5yr_AIG']\n"
     ]
    }
   ],
   "source": [
    "# Create Directory to Save Additional Tables not in Final Dataset\n",
    "adlcd = outputDir+'AddlTables'\n",
    "if not os.path.exists(adlcd):\n",
    "    os.makedirs(adlcd)\n",
    "adlcd = adlcd + '/'\n",
    "\n",
    "\n",
    "#***********************************************************************\n",
    "#READY Accountability Drill Down Reshape\n",
    "#***********************************************************************\n",
    "#Shorten Standard column name for clean code\n",
    "accDrillDown.rename(columns={'Standard (CCR - Level 4 & 5, GLP - Level 3 & Above)':'Standard'}, inplace=True)\n",
    "#Shorten Standard row values before table pivot\n",
    "accDrillDown['Standard'] = accDrillDown['Standard'].map({'College and Career Ready'       :'CACR'\n",
    "                                                          ,'Grade Level Proficient'       :'GLP'\n",
    "                                                          ,'Standard (4 Year)'            :'4yr'\n",
    "                                                          ,'Extended (5 year)'            :'5yr'\n",
    "                                                          ,'Met The ACT Benchmark'        :'ACTBenchmark'\n",
    "                                                          ,'Met UNC Minimum'              :'UNCMin'\n",
    "                                                          ,'Percent of Benchmarks Met'    :'BenchmarksMet'\n",
    "                                                          ,'Silver or Better Certificate' :'SilverPlus'\n",
    "                                                         })\n",
    "#Shorten Subject field Names before table pivot\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace('Grades','Gr'))\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace('Grade','Gr'))\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace('The ',''))\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace('All ',''))\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace(' - ',''))\n",
    "accDrillDown['Subject'] = accDrillDown['Subject'].transform(lambda x: x.replace(' ',''))\n",
    "\n",
    "#Pivot table using Subjects and Standards - All Students\n",
    "accDrillDownAll = pd.pivot_table(accDrillDown, values='All Students',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownAll.columns = ['_'.join(col) + '_All' for col in accDrillDownAll.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownAll.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownAllCols = list(accDrillDownAll.columns)\n",
    "f = open(tcd + \"accDrillDownAllCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownAllCols,f)\n",
    "f.close()\n",
    "print (accDrillDownAllCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownAll.to_csv(adlcd + 'accDrillDownAll_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - Female\n",
    "accDrillDownFemale = pd.pivot_table(accDrillDown, values='Female',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownFemale.columns = ['_'.join(col) + '_Female' for col in accDrillDownFemale.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownFemale.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownFemaleCols = list(accDrillDownFemale.columns)\n",
    "f = open(tcd + \"accDrillDownFemaleCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownFemaleCols,f)\n",
    "f.close()\n",
    "print (accDrillDownFemaleCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownFemale.to_csv(adlcd + 'accDrillDownFemale_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - Male\n",
    "accDrillDownMale = pd.pivot_table(accDrillDown, values='Male',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownMale.columns = ['_'.join(col) + '_Male' for col in accDrillDownMale.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownMale.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownMaleCols = list(accDrillDownMale.columns)\n",
    "f = open(tcd + \"accDrillDownMaleCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownMaleCols,f)\n",
    "f.close()\n",
    "print (accDrillDownMaleCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownMale.to_csv(adlcd + 'accDrillDownMale_15.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "#Pivot table using Subjects and Standards - American Indian\n",
    "accDrillDownAmericanIndian = pd.pivot_table(accDrillDown, values='American Indian'\n",
    "                                            ,index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownAmericanIndian.columns = ['_'.join(col) + '_AmericanIndian' for col in accDrillDownAmericanIndian.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownAmericanIndian.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownAmericanIndianCols = list(accDrillDownAmericanIndian.columns)\n",
    "f = open(tcd + \"accDrillDownAmericanIndianCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownAmericanIndianCols,f)\n",
    "f.close()\n",
    "print (accDrillDownAmericanIndianCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownAmericanIndian.to_csv(adlcd + 'accDrillDownAmericanIndian_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - Asian\n",
    "accDrillDownAsian = pd.pivot_table(accDrillDown, values='Asian',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownAsian.columns = ['_'.join(col) + '_Asian' for col in accDrillDownAsian.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownAsian.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownAsianCols = list(accDrillDownAsian.columns)\n",
    "f = open(tcd + \"accDrillDownAsianCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownAsianCols,f)\n",
    "f.close()\n",
    "print (accDrillDownAsianCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownAsian.to_csv(adlcd + 'accDrillDownAsian_15.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "#Pivot table using Subjects and Standards - Black\n",
    "accDrillDownBlack = pd.pivot_table(accDrillDown, values='Black',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownBlack.columns = ['_'.join(col) + '_Black' for col in accDrillDownBlack.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownBlack.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownBlackCols = list(accDrillDownBlack.columns)\n",
    "f = open(tcd + \"accDrillDownBlackCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownBlackCols,f)\n",
    "f.close()\n",
    "print (accDrillDownBlackCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownBlack.to_csv(adlcd + 'accDrillDownBlack_15.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "#Pivot table using Subjects and Standards - Hispanic\n",
    "accDrillDownHispanic = pd.pivot_table(accDrillDown, values='Hispanic',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownHispanic.columns = ['_'.join(col) + '_Hispanic' for col in accDrillDownHispanic.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownHispanic.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownHispanicCols = list(accDrillDownHispanic.columns)\n",
    "f = open(tcd + \"accDrillDownHispanicCols_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownHispanicCols,f)\n",
    "f.close()\n",
    "print (accDrillDownHispanicCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownHispanic.to_csv(adlcd + 'accDrillDownHispanic_15.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "#Pivot table using Subjects and Standards - Hispanic\n",
    "accDrillDownTwoorMoreRaces = pd.pivot_table(accDrillDown, values='Two or More Races'\n",
    "                                            ,index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownTwoorMoreRaces.columns = ['_'.join(col) + '_TwoorMoreRaces' for col in accDrillDownTwoorMoreRaces.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownTwoorMoreRaces.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownTwoorMoreRacesCols = list(accDrillDownTwoorMoreRaces.columns)\n",
    "f = open(tcd + \"accDrillDownTwoorMoreRaces_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownTwoorMoreRacesCols,f)\n",
    "f.close()\n",
    "print (accDrillDownTwoorMoreRacesCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownTwoorMoreRaces.to_csv(adlcd + 'accDrillDownTwoorMoreRaces_15.csv', sep=',', index=False)\n",
    "\n",
    "\n",
    "#Pivot table using Subjects and Standards - White\n",
    "accDrillDownWhite = pd.pivot_table(accDrillDown, values='White',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownWhite.columns = ['_'.join(col) + '_White' for col in accDrillDownWhite.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownWhite.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownWhiteCols = list(accDrillDownWhite.columns)\n",
    "f = open(tcd + \"accDrillDownWhite_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownWhiteCols,f)\n",
    "f.close()\n",
    "print (accDrillDownWhiteCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownWhite.to_csv(adlcd + 'accDrillDownWhite_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - EDS\n",
    "accDrillDownEDS = pd.pivot_table(accDrillDown, values='EDS',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownEDS.columns = ['_'.join(col) + '_EDS' for col in accDrillDownEDS.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownEDS.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownEDSCols = list(accDrillDownEDS.columns)\n",
    "f = open(tcd + \"accDrillDownEDS_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownEDSCols,f)\n",
    "f.close()\n",
    "print (accDrillDownEDSCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownEDS.to_csv(adlcd + 'accDrillDownEDS_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - LEP\n",
    "accDrillDownLEP = pd.pivot_table(accDrillDown, values='LEP',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownLEP.columns = ['_'.join(col) + '_LEP' for col in accDrillDownLEP.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownLEP.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownLEPCols = list(accDrillDownLEP.columns)\n",
    "f = open(tcd + \"accDrillDownLEP_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownLEPCols,f)\n",
    "f.close()\n",
    "print (accDrillDownLEPCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownLEP.to_csv(adlcd + 'accDrillDownLEP_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - SWD\n",
    "accDrillDownSWD = pd.pivot_table(accDrillDown, values='SWD',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownSWD.columns = ['_'.join(col) + '_SWD' for col in accDrillDownSWD.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownSWD.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownSWDCols = list(accDrillDownSWD.columns)\n",
    "f = open(tcd + \"accDrillDownSWD_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownSWDCols,f)\n",
    "f.close()\n",
    "print (accDrillDownSWDCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownSWD.to_csv(adlcd + 'accDrillDownSWD_15.csv', sep=',', index=False)\n",
    "\n",
    "#Pivot table using Subjects and Standards - AIG\n",
    "accDrillDownAIG = pd.pivot_table(accDrillDown, values='AIG',index=['unit_code'],columns=['Subject', 'Standard'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "accDrillDownAIG.columns = ['_'.join(col) + '_AIG' for col in accDrillDownAIG.columns]\n",
    "#Make our index a column for merges later\n",
    "accDrillDownAIG.reset_index(level=0, inplace=True)\n",
    "\n",
    "#############\n",
    "#Save columns\n",
    "accDrillDownAIGCols = list(accDrillDownAIG.columns)\n",
    "f = open(tcd + \"accDrillDownAIG_15.pkl\",\"wb\")\n",
    "pickle.dump(accDrillDownAIGCols,f)\n",
    "f.close()\n",
    "print (accDrillDownAIGCols)\n",
    "\n",
    "#Save the ACC DrillDown data to disk \n",
    "accDrillDownAIG.to_csv(adlcd + 'accDrillDownAIG_15.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'pct_GCE_ALL', 'pct_GCE_LEP', 'pct_GCE_PRM', 'pct_GCE_RPF', 'pct_GCE_SWD', 'pct_PASSED_EOG', 'pct_PASSED_LAA', 'pct_PASSED_RTA', 'pct_PROMOTED', 'pct_RETAINED']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#Read To Achieve (RTA) Reshape\n",
    "#***********************************************************************\n",
    "#get rid of state and district level records (this information is also in the school level records)\n",
    "rta = rta[  (rta['unit_code'] != 'NC-SEA') & (rta['unit_code'].str.contains(\"LEA\") == False)]\n",
    "#Pivot table creating one record per unit_code / school campus \n",
    "rta = pd.pivot_table(rta, values=['pct'],index=['unit_code'],columns=['metrics'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "rta.columns = ['_'.join(col) for col in rta.columns]\n",
    "#Make our index a column for merges later\n",
    "rta.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "rtaCols = list(rta.columns)\n",
    "f = open(tcd + \"rtaCols_15.pkl\",\"wb\")\n",
    "pickle.dump(rtaCols,f)\n",
    "f.close()\n",
    "print (rtaCols)\n",
    "\n",
    "#Save the Read To Achieve data to disk \n",
    "rta.to_csv(adlcd + 'rta_15.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'ACT_pTarget_PctMet', 'ACTWorkKeys_pTarget_PctMet', 'CurrentYearEOC_pTarget_PctMet', 'MathGr10_pTarget_PctMet', 'MathGr3-8_pTarget_PctMet', 'ReadingGr10_pTarget_PctMet', 'ReadingGr3-8_pTarget_PctMet', 'SciGr11_pTarget_PctMet', 'SciGr5&8_pTarget_PctMet', 'TotalTargets_pTarget_PctMet']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#Participation Targets Overall Table Reshape\n",
    "#***********************************************************************\n",
    "\n",
    "#get rid of state and district level records (this information is also in the school level records)\n",
    "pTargets = pTargets[  (pTargets['unit_code'] != 'NC-SEA') & (pTargets['unit_code'].str.contains(\"LEA\") == False)]\n",
    "#Shorten Subject field Names before table pivot\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace('Grades','Gr'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace('Grade','Gr'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace('The ',''))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace('Mathematics','Math'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace(' through ','-'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace(' and ', '&'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace('Science', 'Sci'))\n",
    "pTargets['Part_Targets'] = pTargets['Part_Targets'].transform(lambda x: x.replace(' ', ''))\n",
    "\n",
    "#Pivot table creating one record per unit_code / school campus\n",
    "pTargets = pd.pivot_table(pTargets, values='percent_met',index=['unit_code'],columns=['Part_Targets'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "pTargets.columns = [col + '_pTarget_PctMet' for col in pTargets.columns]\n",
    "#Make our index a column for merges later\n",
    "pTargets.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "pTargetsCols = list(pTargets.columns)\n",
    "f = open(tcd + \"pTargets_15.pkl\",\"wb\")\n",
    "pickle.dump(pTargetsCols,f)\n",
    "f.close()\n",
    "print (pTargetsCols)\n",
    "\n",
    "#**********************  Could go back and add targets assigned and targets met counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'ALL_All Students (Total or Subtotal_ENROLL_sch_pct', 'ECODIS_Economically Disadvantaged_ENROLL_sch_pct', 'F_Female_ENROLL_sch_pct', 'LEP_Limited English Proficiency_ENROLL_sch_pct', 'M_Male_ENROLL_sch_pct', 'MA_Asian_ENROLL_sch_pct', 'MAN_American Indian_ENROLL_sch_pct', 'MB_Black_ENROLL_sch_pct', 'MHL_Hispanic_ENROLL_sch_pct', 'MM_Multiracial_ENROLL_sch_pct', 'MNP_Pacific Islander_ENROLL_sch_pct', 'MW_White_ENROLL_sch_pct', 'WDIS_Students With Disabilities_ENROLL_sch_pct']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#College Enrollment Table Reshape\n",
    "#***********************************************************************\n",
    "\n",
    "#get rid of state and district level records (this information is also in the school level records)\n",
    "collegeEnroll = collegeEnroll[  (collegeEnroll['unit_code'] != 'NC-SEA') \n",
    "                              & (collegeEnroll['unit_code'].str.contains(\"LEA\") == False)]\n",
    "#Pivot table creating one record per unit_code / school campus\n",
    "collegeEnroll = pd.pivot_table(collegeEnroll, values='sch_percent_enrolled'\n",
    "                               ,index=['unit_code'],columns=['subgroup', 'subgroup_name','status'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "collegeEnroll.columns = ['_'.join(col) + '_sch_pct' for col in collegeEnroll.columns]\n",
    "#Make our index a column for merges later\n",
    "collegeEnroll.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "collegeEnrollCols = list(collegeEnroll.columns)\n",
    "f = open(tcd + \"collegeEnrollCols_15.pkl\",\"wb\")\n",
    "pickle.dump(collegeEnrollCols,f)\n",
    "f.close()\n",
    "print (collegeEnrollCols)\n",
    "\n",
    "#******  Could go back and add size - district and size - state features here!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', '0-3 Years_Exp_Pct_Tch', '10+ Years_Exp_Pct_Tch', '4-10 Years_Exp_Pct_Tch', ['unit_code', '0-3 Years_LEA_Exp_Pct_Prin', '10+ Years_LEA_Exp_Pct_Prin', '4-10 Years_LEA_Exp_Pct_Prin']]\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#Educator Experience Table (YOE) Reshape\n",
    "#***********************************************************************\n",
    "\n",
    "#get rid of state and district level records (this information is also in the school level records)\n",
    "yoe = yoe[(yoe['unit_code'] != 'NC-SEA') & (yoe['unit_code'].str.contains(\"LEA\") == False)]\n",
    "#Pivot table creating one record per unit_code / school campus\n",
    "yoeTch = pd.pivot_table(yoe, values='pct_tch',index=['unit_code'],columns=['Experience'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "yoeTch.columns = [col + '_Exp_Pct_Tch' for col in yoeTch.columns]\n",
    "#Make our index a column for merges later\n",
    "yoeTch.reset_index(level=0, inplace=True)\n",
    "\n",
    "#Pivot table creating one record per unit_code / school campus for principals\n",
    "yoePrin = pd.pivot_table(yoe, values='lea_pct_prin',index=['unit_code'],columns=['Experience'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "yoePrin.columns = [col + '_LEA_Exp_Pct_Prin' for col in yoePrin.columns]\n",
    "#Make our index a column for merges later\n",
    "yoePrin.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "yoeCols = list(yoeTch.columns)\n",
    "yoeCols.append(list(yoePrin.columns))\n",
    "f = open(tcd + \"yoeCols_15.pkl\",\"wb\")\n",
    "pickle.dump(yoeCols,f)\n",
    "f.close()\n",
    "print (yoeCols)\n",
    "\n",
    "#******  Could go back and add pct_tch - district and pct_tch - state features here!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit_code', 'Accomplished_PRIN_Standard 1_Pct', 'Accomplished_PRIN_Standard 2_Pct', 'Accomplished_PRIN_Standard 3_Pct', 'Accomplished_PRIN_Standard 4_Pct', 'Accomplished_PRIN_Standard 5_Pct', 'Accomplished_PRIN_Standard 6_Pct', 'Accomplished_PRIN_Standard 7_Pct', 'Accomplished_TCHR_Standard 1_Pct', 'Accomplished_TCHR_Standard 2_Pct', 'Accomplished_TCHR_Standard 3_Pct', 'Accomplished_TCHR_Standard 4_Pct', 'Accomplished_TCHR_Standard 5_Pct', 'Developing_PRIN_Standard 1_Pct', 'Developing_PRIN_Standard 2_Pct', 'Developing_PRIN_Standard 3_Pct', 'Developing_PRIN_Standard 4_Pct', 'Developing_PRIN_Standard 5_Pct', 'Developing_PRIN_Standard 6_Pct', 'Developing_PRIN_Standard 7_Pct', 'Developing_TCHR_Standard 1_Pct', 'Developing_TCHR_Standard 2_Pct', 'Developing_TCHR_Standard 3_Pct', 'Developing_TCHR_Standard 4_Pct', 'Developing_TCHR_Standard 5_Pct', 'Distinguished_PRIN_Standard 1_Pct', 'Distinguished_PRIN_Standard 2_Pct', 'Distinguished_PRIN_Standard 3_Pct', 'Distinguished_PRIN_Standard 4_Pct', 'Distinguished_PRIN_Standard 5_Pct', 'Distinguished_PRIN_Standard 6_Pct', 'Distinguished_PRIN_Standard 7_Pct', 'Distinguished_TCHR_Standard 1_Pct', 'Distinguished_TCHR_Standard 2_Pct', 'Distinguished_TCHR_Standard 3_Pct', 'Distinguished_TCHR_Standard 4_Pct', 'Distinguished_TCHR_Standard 5_Pct', 'Does Not Meet Expected Growth_PRIN_Standard 8_Pct', 'Does Not Meet Expected Growth_TCHR_Standard 6_Pct', 'Exceeds Expected Growth_PRIN_Standard 8_Pct', 'Exceeds Expected Growth_TCHR_Standard 6_Pct', 'Meets Expected Growth_PRIN_Standard 8_Pct', 'Meets Expected Growth_TCHR_Standard 6_Pct', 'Not Demostrated_PRIN_Standard 1_Pct', 'Not Demostrated_PRIN_Standard 2_Pct', 'Not Demostrated_PRIN_Standard 3_Pct', 'Not Demostrated_PRIN_Standard 4_Pct', 'Not Demostrated_PRIN_Standard 5_Pct', 'Not Demostrated_PRIN_Standard 6_Pct', 'Not Demostrated_PRIN_Standard 7_Pct', 'Not Demostrated_TCHR_Standard 1_Pct', 'Not Demostrated_TCHR_Standard 2_Pct', 'Not Demostrated_TCHR_Standard 3_Pct', 'Not Demostrated_TCHR_Standard 4_Pct', 'Not Demostrated_TCHR_Standard 5_Pct', 'Proficient_PRIN_Standard 1_Pct', 'Proficient_PRIN_Standard 2_Pct', 'Proficient_PRIN_Standard 3_Pct', 'Proficient_PRIN_Standard 4_Pct', 'Proficient_PRIN_Standard 5_Pct', 'Proficient_PRIN_Standard 6_Pct', 'Proficient_PRIN_Standard 7_Pct', 'Proficient_TCHR_Standard 1_Pct', 'Proficient_TCHR_Standard 2_Pct', 'Proficient_TCHR_Standard 3_Pct', 'Proficient_TCHR_Standard 4_Pct', 'Proficient_TCHR_Standard 5_Pct']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "#Educator Effectiveness Reshape\n",
    "#***********************************************************************\n",
    "#It does not appear that this table reports values of 0 for missing categories, imputing NA to 0 for all missing values  \n",
    "effectiveness.percent.fillna(0, inplace=True)\n",
    "#Pivot table creating one record per unit_code / school campus\n",
    "effectiveness = pd.pivot_table(effectiveness, values='percent',index=['unit_code'],columns=['level','Role','STANDARD'])\n",
    "#concatenate multiindex column names using a list comprehension.\n",
    "effectiveness.columns = ['_'.join(col) + '_Pct' for col in effectiveness.columns]\n",
    "#Make our index a column for merges later\n",
    "effectiveness.reset_index(level=0, inplace=True)\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "effectivenessCols = list(effectiveness.columns)\n",
    "f = open(tcd + \"effectivenessCols_15.pkl\",\"wb\")\n",
    "pickle.dump(effectivenessCols,f)\n",
    "f.close()\n",
    "print (effectivenessCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AsianFemalePct', 'AsianMalePct', 'AsianPct', 'BlackFemalePct', 'BlackMalePct', 'BlackPct', 'HispanicFemalePct', 'HispanicMalePct', 'HispanicPct', 'IndianFemalePct', 'IndianMalePct', 'IndianPct', 'MinorityFemalePct', 'MinorityMalePct', 'MinorityPct', 'PacificIslandFemalePct', 'PacificIslandMalePct', 'PacificIslandPct', 'School Name', 'TwoOrMoreFemalePct', 'TwoOrMoreMalePct', 'TwoOrMorePct', 'WhiteFemalePct', 'WhiteMalePct', 'WhitePct', 'unit_code']\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "# Statistical Profiles - Student Body Racial Compositions at the School Level Reshape\n",
    "#\n",
    "# Statistical Profiles data are already one record per public school but must be converted to percentages\n",
    "# Creates a new dataset - ec_pupils_pct.csv\n",
    "#\n",
    "#***********************************************************************\n",
    "\n",
    "#Create Racial Composition summary variables\n",
    "ec_pupils['Indian'] = ec_pupils['Indian Male'] + ec_pupils['Indian Female']\n",
    "ec_pupils['Asian'] = ec_pupils['Asian Male'] + ec_pupils['Asian Female']\n",
    "ec_pupils['Hispanic'] = ec_pupils['Hispanic Male'] + ec_pupils['Hispanic Female']\n",
    "ec_pupils['Black'] = ec_pupils['Black Male'] + ec_pupils['Black Female']\n",
    "ec_pupils['White'] = ec_pupils['White Male'] + ec_pupils['White Female']\n",
    "ec_pupils['Pacific Island'] = ec_pupils['Pacific Island Male'] + ec_pupils['Pacific Island Female']\n",
    "ec_pupils['Two or  More'] = ec_pupils['Two or  More Male'] + ec_pupils['Two or  More Female']\n",
    "\n",
    "#The original total field is corrupted with non-printable characters and will not convert to int or float \n",
    "ec_pupils.drop(['Total'], axis=1, inplace=True)\n",
    "#Create a new totals field by summing race composition fields\n",
    "ec_pupils['Total'] = ec_pupils['Indian'] + ec_pupils['Asian'] + \\\n",
    "                     ec_pupils['Hispanic'] + ec_pupils['Black'] + \\\n",
    "                     ec_pupils['White'] + ec_pupils['Pacific Island'] + ec_pupils['Two or  More']\n",
    "#Convert Totals to float64 for division later\n",
    "ec_pupils['Total'] = ec_pupils['Total'].astype(np.float64)\n",
    "\n",
    "#Create Minority summary variables \n",
    "ec_pupils['Minority Male'] = ec_pupils['Indian Male'] + ec_pupils['Asian Male'] \\\n",
    "                           + ec_pupils['Hispanic Male'] + ec_pupils['Black Male'] \\\n",
    "                           + ec_pupils['Pacific Island Male'] + ec_pupils['Two or  More Male'] \n",
    "ec_pupils['Minority Female'] = ec_pupils['Indian Female'] + ec_pupils['Asian Female'] \\\n",
    "                           + ec_pupils['Hispanic Female'] + ec_pupils['Black Female'] \\\n",
    "                           + ec_pupils['Pacific Island Female'] + ec_pupils['Two or  More Female']\n",
    "ec_pupils['Minority'] = ec_pupils['Minority Male'] + ec_pupils['Minority Female']\n",
    "\n",
    "#Create Student Body Racial Composition PERCENTAGES at the School Level\n",
    "ec_pupils_pct = pd.DataFrame({'unit_code'   : ec_pupils['unit_code']\n",
    "                            , 'School Name' : ec_pupils['___School Name___']\n",
    "                            , 'IndianPct'   : ec_pupils['Indian'] / ec_pupils['Total']  \n",
    "                            , 'AsianPct'    : ec_pupils['Asian'] / ec_pupils['Total']\n",
    "                            , 'HispanicPct' : ec_pupils['Hispanic'] / ec_pupils['Total']\n",
    "                            , 'BlackPct'    : ec_pupils['Black'] / ec_pupils['Total']\n",
    "                            , 'WhitePct'    : ec_pupils['White'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandPct': ec_pupils['Pacific Island'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMorePct': ec_pupils['Two or  More'] / ec_pupils['Total']\n",
    "                            , 'MinorityPct' : ec_pupils['Minority'] / ec_pupils['Total']\n",
    "                            \n",
    "                              \n",
    "                            , 'IndianMalePct'   : ec_pupils['Indian Male'] / ec_pupils['Total']  \n",
    "                            , 'AsianMalePct'    : ec_pupils['Asian Male'] / ec_pupils['Total']\n",
    "                            , 'HispanicMalePct' : ec_pupils['Hispanic Male'] / ec_pupils['Total']\n",
    "                            , 'BlackMalePct'    : ec_pupils['Black Male'] / ec_pupils['Total']\n",
    "                            , 'WhiteMalePct'    : ec_pupils['White Male'] / ec_pupils['Total']\n",
    "                            , 'PacificIslandMalePct': ec_pupils['Pacific Island Male'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreMalePct': ec_pupils['Two or  More Male'] / ec_pupils['Total']  \n",
    "                            , 'MinorityMalePct' : ec_pupils['Minority Male'] / ec_pupils['Total']\n",
    "                                                          \n",
    "                            , 'IndianFemalePct'   : ec_pupils['Indian Female'] / ec_pupils['Total']  \n",
    "                            , 'AsianFemalePct'    : ec_pupils['Asian Female'] / ec_pupils['Total']\n",
    "                            , 'HispanicFemalePct' : ec_pupils['Hispanic Female'] / ec_pupils['Total']\n",
    "                            , 'BlackFemalePct'    : ec_pupils['Black Female'] / ec_pupils['Total']\n",
    "                            , 'WhiteFemalePct'    : ec_pupils['White Female'] / ec_pupils['Total']\n",
    "                            , 'MinorityFemalePct' : ec_pupils['Minority Female'] / ec_pupils['Total'] \n",
    "                            , 'PacificIslandFemalePct': ec_pupils['Pacific Island Female'] / ec_pupils['Total']\n",
    "                            , 'TwoOrMoreFemalePct': ec_pupils['Two or  More Female'] / ec_pupils['Total']\n",
    "                             })\n",
    "\n",
    "## Save Columns to Pickle File\n",
    "ec_pupils_pct_Cols = list(ec_pupils_pct.columns)\n",
    "f = open(tcd + \"ec_pupils_pct_Cols_15.pkl\",\"wb\")\n",
    "pickle.dump(ec_pupils_pct_Cols,f)\n",
    "f.close()\n",
    "print (ec_pupils_pct_Cols)\n",
    "\n",
    "#Save the racial composition percentage data to disk \n",
    "ec_pupils_pct.to_csv(adlcd + 'ec_pupils_pct_15.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all datasets to one master dataset with one record per school \n",
    "**Starting with the profiles table we left outer join on unit_code, merging data from each reshaped table into one master record.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************Start: Profile Data*********************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 3043\n",
      "Columns: 35 entries, vphone_ad to url\n",
      "dtypes: float64(7), int64(1), object(27)\n",
      "memory usage: 727.0+ KB\n",
      "*********************************After: Profile Metric Data**************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 47 entries, vphone_ad to Math I_Size\n",
      "dtypes: float64(19), int64(1), object(27)\n",
      "memory usage: 969.4+ KB\n",
      "*********************************After: Funding Data*********************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 85 entries, vphone_ad to st_building_expense_pct\n",
      "dtypes: float64(52), int64(2), object(31)\n",
      "memory usage: 1.7+ MB\n",
      "*********************************After: SPG Data*************************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 108 entries, vphone_ad to State Gap Compared\n",
      "dtypes: float64(67), int64(2), object(39)\n",
      "memory usage: 2.1+ MB\n",
      "*********************************After: Participation Targets Data*******************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 118 entries, vphone_ad to TotalTargets_pTarget_PctMet\n",
      "dtypes: float64(77), int64(2), object(39)\n",
      "memory usage: 2.3+ MB\n",
      "*********************************After: School Indicators Data***********************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 145 entries, vphone_ad to st_ib_pct_4_or_above\n",
      "dtypes: float64(98), int64(2), object(45)\n",
      "memory usage: 2.9+ MB\n",
      "*********************************After: Specialized Course Enrollment****************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 162 entries, vphone_ad to st_univ_college_courses\n",
      "dtypes: float64(111), int64(2), object(49)\n",
      "memory usage: 3.2+ MB\n",
      "*********************************After: College Enrollment***************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 175 entries, vphone_ad to WDIS_Students With Disabilities_ENROLL_sch_pct\n",
      "dtypes: float64(124), int64(2), object(49)\n",
      "memory usage: 3.5+ MB\n",
      "*********************************After: Environment Data*****************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 218 entries, vphone_ad to SRC_Grades_Devices_Sent_Home\n",
      "dtypes: float64(157), int64(2), object(59)\n",
      "memory usage: 4.3+ MB\n",
      "*********************************After: Personnel Data*******************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 290 entries, vphone_ad to st_prin_other_pct\n",
      "dtypes: float64(222), int64(5), object(63)\n",
      "memory usage: 5.7+ MB\n",
      "*********************************After: Years of Experience Teachers Data************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 293 entries, vphone_ad to 4-10 Years_Exp_Pct_Tch\n",
      "dtypes: float64(225), int64(5), object(63)\n",
      "memory usage: 5.8+ MB\n",
      "*********************************After: Years of Experience Principals Data**********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 296 entries, vphone_ad to 4-10 Years_LEA_Exp_Pct_Prin\n",
      "dtypes: float64(228), int64(5), object(63)\n",
      "memory usage: 5.9+ MB\n",
      "*********************************After: Educator Effectiveness Data******************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 362 entries, vphone_ad to Proficient_TCHR_Standard 5_Pct\n",
      "dtypes: float64(294), int64(5), object(63)\n",
      "memory usage: 7.2+ MB\n",
      "*********************************After: Racial Composition Data**********************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 387 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(318), int64(5), object(64)\n",
      "memory usage: 7.7+ MB\n",
      "*********************************After: Deleting Duplicated Columns*********\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 362 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(315), int64(3), object(44)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remove state and district level profiles before performing campus level merges\n",
    "profile = profile[(profile['unit_code'] != 'NC-SEA') & (profile['unit_code'].str.contains(\"LEA\") == False)]\n",
    "\n",
    "print('*********************************Start: Profile Data*********************************')\n",
    "profile.info(verbose=False)\n",
    "\n",
    "#Merge profile and profileMetric data\n",
    "PublicSchools = profile.merge(profileMetric,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Profile Metric Data**************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Delete duplicate / incomplete record in funding table before merge\n",
    "dupRecord = funding[(funding['unit_code'] == '76A000') & (funding['total_expense_num'].isna())].index\n",
    "funding.drop(dupRecord, inplace=True)\n",
    "\n",
    "#Merge funding data\n",
    "PublicSchools = PublicSchools.merge(funding,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Funding Data*********************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge SPG data\n",
    "PublicSchools = PublicSchools.merge(spg,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: SPG Data*************************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownAll data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownAll,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownAll Data*************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownFemale data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownFemale,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownFemale Data**********************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownMale data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownMale,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownMale Data************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownAmericanIndian data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownAmericanIndian,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownAmericanIndian Data**************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownAsian data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownAsian,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownAsian Data***********************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownBlack data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownBlack,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownBlack Data***********************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownHispanic data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownHispanic,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownHispanic Data********************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownTwoorMoreRaces data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownTwoorMoreRaces,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownTwoorMoreRaces Data**************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownWhite data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownWhite,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownWhite Data***********************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownEDS data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownEDS,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownEDS Data*************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownLEP data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownLEP,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownLEP Data*************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownSWD data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownSWD,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownSWD Data*************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge accDrillDownAIG data\n",
    "# PublicSchools = PublicSchools.merge(accDrillDownAIG,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: accDrillDownAIG Data*************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "# #Merge RTA data\n",
    "# PublicSchools = PublicSchools.merge(rta,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "# print('*********************************After: RTA Data*************************************')\n",
    "# PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Participation Targets data\n",
    "PublicSchools = PublicSchools.merge(pTargets,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Participation Targets Data*******************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge School Indicators data\n",
    "PublicSchools = PublicSchools.merge(schoolInds,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: School Indicators Data***********************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Specialized Course Enrollment data\n",
    "PublicSchools = PublicSchools.merge(sce,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Specialized Course Enrollment****************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge College Enrollment data\n",
    "PublicSchools = PublicSchools.merge(collegeEnroll,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: College Enrollment***************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Delete duplicate / incomplete record in Environment table before merge\n",
    "dupRecord = environment[(environment['unit_code'] == '76A000') & (environment['avg_daily_attend_pct'].isna())].index\n",
    "environment.drop(dupRecord, inplace=True)\n",
    "\n",
    "#Merge Environment data\n",
    "PublicSchools = PublicSchools.merge(environment,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Environment Data*****************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Delete duplicate / incomplete record in personnel table before merge\n",
    "dupRecord = personnel[(personnel['unit_code'] == '76A000') & (personnel['lateral_teach_pct'].isna())].index\n",
    "personnel.drop(dupRecord, inplace=True)\n",
    "\n",
    "#Merge personnel data\n",
    "PublicSchools = PublicSchools.merge(personnel,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Personnel Data*******************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Years of Experience Teachers data\n",
    "PublicSchools = PublicSchools.merge(yoeTch,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Years of Experience Teachers Data************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Years of Experience Principals data\n",
    "PublicSchools = PublicSchools.merge(yoePrin,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Years of Experience Principals Data**********')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Educator Effectiveness data\n",
    "PublicSchools = PublicSchools.merge(effectiveness,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Educator Effectiveness Data******************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Merge Racial Composition data\n",
    "PublicSchools = PublicSchools.merge(ec_pupils_pct,how='left',on='unit_code', suffixes=('', '_Drop'))\n",
    "\n",
    "print('*********************************After: Racial Composition Data**********************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Delete all of the duplicate / overlapping columns \n",
    "#i.e. When two tables have columns with identical names, the column from the table inside the merge() is deleted.\n",
    "dropCols = [x for x in PublicSchools.columns if x.endswith('_Drop')]\n",
    "PublicSchools = PublicSchools.drop(dropCols, axis=1)\n",
    "\n",
    "print('*********************************After: Deleting Duplicated Columns*********')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ** *The report above shows changes to the final dataset's column and row counts as each flattened raw dataset is merged into the final Public School Datasets* **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Save the Final Public School Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************All Public Schools****************************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2585 entries, 0 to 2584\n",
      "Columns: 362 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(315), int64(3), object(44)\n",
      "memory usage: 7.2+ MB\n",
      "*********************************Regular Public High Schools*******************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 480 entries, 0 to 2583\n",
      "Columns: 362 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(315), int64(3), object(44)\n",
      "memory usage: 1.3+ MB\n",
      "*********************************Regular Public Middle Schools******************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 537 entries, 3 to 2581\n",
      "Columns: 362 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(315), int64(3), object(44)\n",
      "memory usage: 1.5+ MB\n",
      "*********************************Regular Public Elementary Schools**************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1298 entries, 1 to 2584\n",
      "Columns: 362 entries, vphone_ad to WhitePct\n",
      "dtypes: float64(315), int64(3), object(44)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Save the master file to disk\n",
    "PublicSchools.to_csv(outputDir + 'PublicSchools' + str(schoolYear) + '.csv', sep=',', index=False)\n",
    "\n",
    "print('*********************************All Public Schools****************************')\n",
    "PublicSchools.info(verbose=False)\n",
    "\n",
    "#Filter regular public high schools\n",
    "HighSchools = PublicSchools[((PublicSchools.category_cd == 'H') | \n",
    "                             (PublicSchools.category_cd == 'T') | \n",
    "                             (PublicSchools.category_cd == 'A')) &\n",
    "                             (PublicSchools.student_num > 0) & \n",
    "                             (PublicSchools.type_cd == 'P') & \n",
    "                             (PublicSchools.school_type_txt == 'Regular School')\n",
    "                            ]\n",
    "\n",
    "#Save the file to disk\n",
    "HighSchools.to_csv(outputDir + 'PublicHighSchools' + str(schoolYear) + '.csv', sep=',', index=False)\n",
    "\n",
    "print('*********************************Regular Public High Schools*******************')\n",
    "HighSchools.info(verbose=False)\n",
    "\n",
    "#Filter regular public middle schools\n",
    "MiddleSchools = PublicSchools[((PublicSchools.category_cd == 'M') | \n",
    "                               (PublicSchools.category_cd == 'T') | \n",
    "                               (PublicSchools.category_cd == 'A') |\n",
    "                               (PublicSchools.category_cd == 'I')) &\n",
    "                               (PublicSchools.student_num > 0) & \n",
    "                               (PublicSchools.type_cd == 'P') & \n",
    "                               (PublicSchools.school_type_txt == 'Regular School')\n",
    "                             ]\n",
    "\n",
    "#Save the file to disk\n",
    "MiddleSchools.to_csv(outputDir + 'PublicMiddleSchools' + str(schoolYear) + '.csv', sep=',', index=False)\n",
    "\n",
    "print('*********************************Regular Public Middle Schools******************')\n",
    "MiddleSchools.info(verbose=False)\n",
    "\n",
    "\n",
    "#Filter regular elementary high schools\n",
    "ElementarySchools = PublicSchools[((PublicSchools.category_cd == 'E') | \n",
    "                                   (PublicSchools.category_cd == 'I') | \n",
    "                                   (PublicSchools.category_cd == 'A')) &\n",
    "                                   (PublicSchools.student_num > 0) & \n",
    "                                   (PublicSchools.type_cd == 'P') & \n",
    "                                   (PublicSchools.school_type_txt == 'Regular School')\n",
    "                                 ]\n",
    "\n",
    "#Save the file to disk\n",
    "ElementarySchools.to_csv(outputDir + 'PublicElementarySchools' + str(schoolYear) + '.csv', sep=',', index=False)\n",
    "\n",
    "print('*********************************Regular Public Elementary Schools**************')\n",
    "ElementarySchools.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
